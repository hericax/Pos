{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "PDsi3-sMG2by",
    "nbgrader": {
     "checksum": "38fd99a0752804fa58a04ee088c6b296",
     "grade": false,
     "grade_id": "localiza",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "![](unimed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "01OoJRv6G2b1",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Pré-processamento de dados\n",
    "\n",
    "Neste hands-on, queremos aplicar técnicas de pré-processamento de dados para nos auxiliar em tarefas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "YApG2tX2G2b3",
    "nbgrader": {
     "checksum": "3d6bc6467e585480a4e7be4c5176e501",
     "grade": false,
     "grade_id": "RO_bibliotecas",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "qMeuqe2iG2b_",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Parte 1 - Titanic\n",
    "\n",
    "Nesta primeira parte, vamos focar principalmente nas tarefas de limpeza e transformação de dados. Vamos utilizar novamente os dados dos passageiros do Titanic que estão disponíveis no arquivo **titanic_data.csv**.\n",
    "\n",
    "Primeiro precisamos fazer a leitura do arquivo, para isso utlizaremos a função do pandas **read_csv('nome_do_arquivo.csv')**, que faz a leitura dos dados e os armazena em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbwDjcRUG2cB"
   },
   "outputs": [],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável titanic e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEUczoRIG2cF"
   },
   "outputs": [],
   "source": [
    "\"\"\"Renomeie as colunas do DataFrame para facilitar o entendimento\"\"\"\n",
    "\n",
    "titanic.columns = ['IdPassageiro','Sobreviveu?','Classe','Nome','Sexo','Idade','Irmãos/Cônjuge','Pais/Crianças','Bilhete','Tarifa','Cabine','Embarque']\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN98LvgFG2cJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Verifique os tipos de cada coluna do dataframe com o auxilio do atributo dtypes\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_FdQi_4G2cN"
   },
   "outputs": [],
   "source": [
    "\"\"\"Remova as colunas IdPassageiro, Bilhete e Cabine do DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rObS74uYIAlQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "OZA0IfXRG2cQ",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando estamos trabalhando com dados, é importante saber algumas informações importantes sobre eles. Por exemplo, valores máximo e mínimo de cada atributo, sua média, desvio padrão, dentre outras. A função `describe` do pandas nos ajuda com essa tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zccSiPdRG2cS"
   },
   "outputs": [],
   "source": [
    "\"\"\"Verifique as informações importantes dos atributos do dataframe do titanic\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "HtrN09a3G2cX",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Observe que, apesar de o DataFrame possuir 891 registros, a coluna *idade* retorna uma quantidade de 714 registros. Isso pode ocorrer devido à presença de valores nulos/inválidos no conjunto de dados. No caso do Titanic, pode ser que a idade de certos passageiros fosse desconhecida ou não tenha sido recuperada.\n",
    "\n",
    "Dados faltantes ou incorretos acontecem com bastante frequência, e é nossa tarefa tratá-los da forma correta. Aqui, vamos definir a idade dos passageiros que estão faltando com o valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkJO-hNhG2ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Substitua os valores nulos de Idade por zero e verifique novamente as estatísticas para o DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIJCRLTCG2cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados da coluna Idade do DataFrame. Logo após, utilize o comando plt.show() \n",
    "para exibir a figura sem saídas de texto antes. \n",
    "    Dica: o pandas possui uma função que ajuda bastante nessa tarefa. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "hDaPrcMzG2cm",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Podemos querer normalizar atributos para oberservá-los em um intervalo de valores mais bem controlado. Vamos então normalizar o valor da coluna Tarifa no intervalo $[0,1]$ utilizando a normalização **min-max**, que é dada pela **fórmula**:\n",
    "\n",
    "$$v' = \\frac{v-min_A}{max_A - min_A}(nmax_A - nmin_A) + nmin_A$$\n",
    "\n",
    "onde:\n",
    "* $[nmin_A, nmax_A]$ é o intervalo no qual você deseja normalizar seus dados (no nosso caso, $[0,1]$)\n",
    "* $min_A$ e $max_A$ são os atuais valores mínimo e máximo da coluna, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOpnFiG8G2cr"
   },
   "outputs": [],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeNorm' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Salve os valores máximo e mínimo da coluna em variáveis antes de efetuar a transformação.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqiA4Wv0G2cy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados normalizados da coluna Idade do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PznhbJC4G2c3"
   },
   "source": [
    "Outra técnica importante é a **discretização** dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVubKmK0G2c4"
   },
   "outputs": [],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeDisc' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Para pessoas entre 0 e 17 anos, atribua o valor 'Criança'.\n",
    "    Para pessoas entre 18 e 59 anos, atribua o valor 'Adulto'.\n",
    "    Para pessoas entre 60 e 80 anos, atribua o valor 'Idoso'.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxDYr_n6G2c7"
   },
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados discretizados da coluna IdadeDisc do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \n",
    "    Dica: confira a função value_counts() do pandas.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "er9arVUSG2dB",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Após a discretização dos dados, podemos fazer o processo de **binarização**, isto é, criar uma coluna para cada categoria que contém os valores 0 ou 1 que indicam se cada linha pertence ou não a esta categoria. Isso é importante pois a grande maioria dos algoritmos e funções dos pacotes do Python não aceitam dados categóricos, sendo necessário discretizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpAivGMRG2dC"
   },
   "outputs": [],
   "source": [
    "\"\"\"Para cada uma das categorias criadas anteriormente (Criança, Adulto e Idoso), crie uma nova coluna\n",
    "que indicará se a linha faz parte da categoria (recebendo o valor 1) ou não (valor 0). \n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2YbzS39WG2dF",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Parte 2 - Iris\n",
    "\n",
    "Nesta parte, vamos utilizar dados sobre a classificação de plantas *Iris* a partir de suas características.\n",
    "\n",
    "Descrição dos Dados: http://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "Os dados estarão disponíveis no arquivo **iris.csv**\n",
    "\n",
    "Para este exercícios utilizaremos a biblioteca **pandas** para a leitura e manipulação dos dados. Para o trabalho de redução de dimensionalidade com **PCA** utilizaremos a implementação disponibilizada pelo <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">Scikit-Learn</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "n_pS5YSUG2dH",
    "nbgrader": {
     "checksum": "815dda85265870382dac997f48c79f98",
     "grade": false,
     "grade_id": "RO_leitura_dados",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Como este é nosso primeiro contato com a base **iris**, é importante conhecermos sua estrutura e quais as informações presentes. Ao trabalharmos com DataFrames pandas podemos utilizar a função **head()** para termos uma visão de como o arquivo está configurado, exibindo por default as 5 primeiras linhas do DataFrame.\n",
    "\n",
    "**Obs.**: a função **head()** pode receber como parâmetro o nº de linhas a ser exibido, caso queiramos ver as 10 primeiras linhas do DataFrame basta utilizarmos **head(10)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "FinoH-H6G2dJ",
    "nbgrader": {
     "checksum": "952427661d280a38c3aa828c70f07e4b",
     "grade": true,
     "grade_id": "MG_leitura_dados",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável data e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "mIS8JoiIG2dP",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "O **PCA** (Principal Component Analysis), método de redução de dimensionalidade que utilizaremos mais adiante, deve ser aplicado apenas em dados numéricos. Portanto, devemos ter certeza de que todas as colunas do nosso dataframe satisfazem a este requisito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Cp7pKznsG2dQ",
    "nbgrader": {
     "checksum": "8b8efed70991396343dbda54007bc045",
     "grade": false,
     "grade_id": "RO_tipos",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Verifique o tipo dos dados de cada coluna do dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2yJ9qJnkG2dW",
    "nbgrader": {
     "checksum": "5b7bf63077b8d6eb675dd81e5614da5e",
     "grade": false,
     "grade_id": "RO_drop_coluna",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A princípio a coluna **species** não será necessária, devemos então salvá-la em uma nova variável e depois dropá-la de nosso dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "GiaE3v4PG2da",
    "nbgrader": {
     "checksum": "73ecc0ae05b0efcb804403a524c3d846",
     "grade": false,
     "grade_id": "AT_cria_variavel",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crie uma nova variável chamada species que receba os dados contidos na coluna 'species' de seu Dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "pMSC2SlHG2de",
    "nbgrader": {
     "checksum": "85e461ad93c30e755a09a2246aa29731",
     "grade": false,
     "grade_id": "cell-05ebff8e1ce4a432",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora já podemos dropá-la do nosso DataFrame. Para isto utilizaremos a função **drop(columns = , axis = , inplace = )**.\n",
    "\n",
    "**columns:** recebe a lista de colunas a serem dropadas.\n",
    "\n",
    "**axis:** indica em qual eixo o drop será realizado, <b>1</b> para colunas e **0** para linhas\n",
    "\n",
    "**inplace:** quando **True** a operação não gera nenhum retorno, sendo realizada na própria variável. Quando **False** (default) a alteração é efetuada apenas no retorno, precisando ser salva em alguma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "EBCNF5FQG2df",
    "nbgrader": {
     "checksum": "7a0a26170160f9d29d04704fd57117b3",
     "grade": false,
     "grade_id": "AG_drop_coluna",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crie uma variável df onde a mesma receba o retorno da função drop descrita acima. \n",
    "Em seguida realize a operação de forma implícita, gerando ao final 2 dataframes iguais.\"\"\"\n",
    "df = data.drop('species', axis = 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Vv8dzK5QG2dj",
    "nbgrader": {
     "checksum": "663d4dde4e90e4ed9668915609c1b0e5",
     "grade": true,
     "grade_id": "AT_drop_coluna",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Verifica se os dois dataframes possuem as mesmas colunas\"\"\"\n",
    "assert data.columns.all() == df.columns.all()\n",
    "\n",
    "\"\"\"Deletamos a variável df pois ela não será mais utilizada.\"\"\"\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "9NkSFBCHG2do",
    "nbgrader": {
     "checksum": "d212d3695e107ac115a0cb9acf27c6a8",
     "grade": false,
     "grade_id": "RO_correlacao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ok, agora que já sabemos que nossos dados são numéricos, podemos olhar para a correlação entre as colunas. Podemos fazer isso de duas formas, olhando para sua matriz de correlação e/ou plotando sua matriz de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "bRQu6TZVG2dq",
    "nbgrader": {
     "checksum": "44cab9c8d2ee6771fa27981de41f9820",
     "grade": false,
     "grade_id": "RO_matriz_correlacao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Para gerar a matriz de correlação de um DataFrame basta utilizar a função .corr()\"\"\"\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "u0_-q6b_G2d0",
    "nbgrader": {
     "checksum": "37cf0e835c7359e9843fdc9423a256a7",
     "grade": false,
     "grade_id": "RO_matriz_dispersao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando começamos a trabalhar com uma biblioteca, é de grande importância que saibamos utilizar sua documentação como auxílio. Clique <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.plotting.scatter_matrix.html\">aqui</a> para acessar a documentação do **scatter_matrix** e gerar a matriz de dispersão dos seus dados. A imagem deverá ter tamanho (10,10) e apresentar em sua diagonal a estimativa de densidade do kernel.\n",
    "\n",
    "**Dica 1:** não se esqueça de utilizar a função plt.show() ao final da célula para que o plot seja gerado de forma limpa (sem gerar retornos em texto da função).\n",
    "\n",
    "**Dica 2:** alterne o valor do parâmetro alpha para obter uma melhor visualização dos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "mL0B6CUhG2d2",
    "nbgrader": {
     "checksum": "fb0fe94327c3d8be0439839a2e98efa4",
     "grade": true,
     "grade_id": "MG_matriz_dispersao",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "cEXOD8AsG2d6",
    "nbgrader": {
     "checksum": "f0d8a6e6f1796dd2b93de6fdf2ab1045",
     "grade": false,
     "grade_id": "RO_title_pca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Utilizando o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "LP3fyAuVG2d7",
    "nbgrader": {
     "checksum": "58be7fbbf54be4d7a1fd90c353fc1b4e",
     "grade": false,
     "grade_id": "RO_pca_1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora vamos utilizar o PCA para reduzir a dimensionalidade dos nossos dados. Não se preocupe em saber os detalhes do PCA, pois vamos aprender com mais profundidade em uma próxima aula. Novamente, vamos nos guiar pela documentação da biblioteca, que você pode acessar clicando <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">aqui</a>.\n",
    "\n",
    "Em um primeiro momento, não devemos passar nenhum valor para o parâmetro **n_components**, dessa forma, podemos visualizar todos os componentes principais gerados e posteriormente decidirmos o número de componentes a serem utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "kUBmJzKnG2d8",
    "nbgrader": {
     "checksum": "67b09a6de724c324c3b59596c2b6a1d0",
     "grade": false,
     "grade_id": "AG_pca_1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crie uma variável pca que receba a função PCA(), em seguida treine o modelo com seus dados \n",
    "e analise a porcentagem de variância explicada por cada componente principal.\n",
    "Dica: arrays possuem a função .cumsum() que permite visualizar o valor acumulativos de seus itens.\"\"\"\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "qNlbFVT1G2eC",
    "nbgrader": {
     "checksum": "8320d654c0efa74bb775cb69d51cfbaa",
     "grade": true,
     "grade_id": "AT_pca_1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert pca.n_components_ == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Vw551HgEG2eG",
    "nbgrader": {
     "checksum": "50a768a6db2a278a577b60679bffe540",
     "grade": false,
     "grade_id": "RO_pca_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Baseando-se na análise realizada acima, já podemos reduzir a dimensionalidade de nossos dados. Agora o parâmetro **n_components** deve ser alterado recebendo como valor o número de componentes principais necessários para explicar no mínimo 97% da variância dos dados. Após a alteração do parâmetro, o modelo deve ser retreinado e em seguida, podemos realizar a transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "59mizDZMG2eI",
    "nbgrader": {
     "checksum": "1be666a0da87316d2d9bc1dca69b7c4e",
     "grade": false,
     "grade_id": "AG_pca_2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crie uma nova variável chamada data_pca, a variável deverá receber os dados transformados pelo PCA,\n",
    "contendo componentes principais suficientes para explicar 97% da variância dos dados.\"\"\"\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "f3FRaxKAG2eN",
    "nbgrader": {
     "checksum": "c57161701220d6eb983bca50e4d209ed",
     "grade": true,
     "grade_id": "AT_pca_2",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"O número de componentes principais não pode ser 4.\"\"\"\n",
    "assert pca.n_components_ != 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "zG0YQeSpG2eS",
    "nbgrader": {
     "checksum": "8d2674c7fe02eed0b49aa59457803869",
     "grade": false,
     "grade_id": "RO_pca_type",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Como podemos ver abaixo, após realizar a transformação dos dados, \n",
    "a biblioteca PCA nos retorna um numpy.ndarray\"\"\"\n",
    "type(data_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KAfgWq22G2eX",
    "nbgrader": {
     "checksum": "6307d8edf42e16544db5302efbfc109b",
     "grade": false,
     "grade_id": "cell-e01b9464684af39e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora que reduzimos a dimensionalidade dos dados, podemos gerar uma visualização aproximada de como os pontos estão distribuídos no espaço, utilizando a função abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "n29ysXC0G2ec",
    "nbgrader": {
     "checksum": "233ce7d8534405bd0b8189edca2e897b",
     "grade": false,
     "grade_id": "RO_plot_scatter",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Gera scatter plot utilizando como coordenada os 2 primeiros componentes principais\"\"\"\n",
    "def plot_scatter(data_pca):\n",
    "    #subplot permite que montemos o plot durante o processo de iteração.\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    #Gera pontos de cores diferentes para cada espécie\n",
    "    for spec in data_pca['species'].unique():    \n",
    "        ax.scatter(data_pca[data_pca['species'] == spec]['PC1'], \n",
    "                   data_pca[data_pca['species'] == spec]['PC2'],\n",
    "                  label = spec)\n",
    "    \n",
    "    #Determina o local onde a legenda será plotada. loc = 0: canto inferior direito\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "-LMX51wlG2ej",
    "nbgrader": {
     "checksum": "91c02dedc40c59987403bc30f3e97b32",
     "grade": false,
     "grade_id": "cell-ca08065919b78c51",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A função **plot_scatter** recebe como parâmetro um DataFrame **data_pca** com 3 colunas, **PC1, PC2, species**. Você deve converter o numpy.ndarray obtido anteriormente em um DataFrame de mesma configuração para que possa utilizar a função e gerar o scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "G2l3zhxDG2ek",
    "nbgrader": {
     "checksum": "4984dab5917ee8fd6d5503447ddde335",
     "grade": false,
     "grade_id": "AG_plot_scatter",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Converta a variável data_pca em um DataFrame de colunas PC1, PC2 e species\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "hBJFVr6tG2en",
    "nbgrader": {
     "checksum": "f528da8e62337acc7b1edcdabddea04a",
     "grade": true,
     "grade_id": "AT_plot_scatter",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_scatter(data_pca)\n",
    "except:\n",
    "    raise ValueError(\"O DataFrame não cumpri os requisitos necessários.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pré-processamento de dados - Exercício.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
