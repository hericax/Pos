{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "PDsi3-sMG2by",
    "nbgrader": {
     "checksum": "38fd99a0752804fa58a04ee088c6b296",
     "grade": false,
     "grade_id": "localiza",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "![](unimed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "01OoJRv6G2b1",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Pré-processamento de dados\n",
    "\n",
    "Neste hands-on, queremos aplicar técnicas de pré-processamento de dados para nos auxiliar em tarefas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "qMeuqe2iG2b_",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Parte 1 - Titanic\n",
    "\n",
    "Nesta primeira parte, vamos focar principalmente nas tarefas de limpeza e transformação de dados. Vamos utilizar novamente os dados dos passageiros do Titanic que estão disponíveis no arquivo **titanic_data.csv**.\n",
    "\n",
    "Primeiro precisamos fazer a leitura do arquivo, para isso utlizaremos a função do pandas **read_csv('nome_do_arquivo.csv')**, que faz a leitura dos dados e os armazena em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável titanic e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic = pd.read_csv(\"Trabalho1/missing-migrants/MissingMigrants-Global.csv\")\n",
    "titanic.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a29812f31d27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#titanic.columns = ['ID','REGIAO_INCIDENTE','DATA_INCIDENTE','ANO_INCIDENTE','MES_INCIDENTE','TOTAL_MORTOS','ESTIMATIVA_MINIMA_MORTOS_MIGRANTES','TOTAL_MORTOS_MIGRANTES','SOBREVIVENTES','MULHERES','HOMENS','CRIANCAS','CAUSA_MORTE','LOCAL_ACIDENTE','INFORMACOES_PESQUINSA','COORDENADA_LOCALIZACAO','ROTA_MIGRACAO','URL','GEOGRAFIA','QUALIDADE_PESQUISA']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Renomeie as colunas do DataFrame para facilitar o entendimento\"\"\"\n",
    "\n",
    "#titanic.columns = ['ID','REGIAO_INCIDENTE','DATA_INCIDENTE','ANO_INCIDENTE','MES_INCIDENTE','TOTAL_MORTOS','ESTIMATIVA_MINIMA_MORTOS_MIGRANTES','TOTAL_MORTOS_MIGRANTES','SOBREVIVENTES','MULHERES','HOMENS','CRIANCAS','CAUSA_MORTE','LOCAL_ACIDENTE','INFORMACOES_PESQUINSA','COORDENADA_LOCALIZACAO','ROTA_MIGRACAO','URL','GEOGRAFIA','QUALIDADE_PESQUISA']\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-12127e8139cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Verifique os tipos de cada coluna do dataframe com o auxilio do atributo dtypes\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e5892017dfe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# titanic.drop(18).head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# titanic.drop(20).head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Remova as colunas IdPassageiro, Bilhete e Cabine do DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# titanic.drop(0).head()\n",
    "# titanic.drop(14).head()\n",
    "# titanic.drop(15).head()\n",
    "# titanic.drop(16).head()\n",
    "# titanic.drop(17).head()\n",
    "# titanic.drop(18).head()\n",
    "# titanic.drop(20).head()\n",
    "titanic.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "OZA0IfXRG2cQ",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando estamos trabalhando com dados, é importante saber algumas informações importantes sobre eles. Por exemplo, valores máximo e mínimo de cada atributo, sua média, desvio padrão, dentre outras. A função `describe` do pandas nos ajuda com essa tarefa."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Web ID</th>\n      <th>Reported Year</th>\n      <th>Number Dead</th>\n      <th>Minimum Estimated Number of Missing</th>\n      <th>Total Dead and Missing</th>\n      <th>Number of Survivors</th>\n      <th>Number of Females</th>\n      <th>Number of Males</th>\n      <th>Number of Children</th>\n      <th>Source Quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5333.000000</td>\n      <td>5333.000000</td>\n      <td>5142.000000</td>\n      <td>503.000000</td>\n      <td>5333.000000</td>\n      <td>749.000000</td>\n      <td>897.000000</td>\n      <td>2813.000000</td>\n      <td>644.000000</td>\n      <td>5333.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43247.885805</td>\n      <td>2016.656104</td>\n      <td>3.287631</td>\n      <td>29.119284</td>\n      <td>5.916370</td>\n      <td>63.607477</td>\n      <td>2.012263</td>\n      <td>1.890864</td>\n      <td>2.476708</td>\n      <td>2.895556</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5186.837212</td>\n      <td>1.237033</td>\n      <td>13.593407</td>\n      <td>67.913216</td>\n      <td>28.051811</td>\n      <td>146.520155</td>\n      <td>2.990100</td>\n      <td>5.510674</td>\n      <td>10.216220</td>\n      <td>1.423257</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>30158.000000</td>\n      <td>2014.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40876.000000</td>\n      <td>2016.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>43504.000000</td>\n      <td>2017.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>45747.000000</td>\n      <td>2018.000000</td>\n      <td>2.000000</td>\n      <td>25.000000</td>\n      <td>3.000000</td>\n      <td>61.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>51592.000000</td>\n      <td>2019.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>1022.000000</td>\n      <td>1950.000000</td>\n      <td>30.000000</td>\n      <td>135.000000</td>\n      <td>250.000000</td>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             Web ID  Reported Year  Number Dead  \\\ncount   5333.000000    5333.000000  5142.000000   \nmean   43247.885805    2016.656104     3.287631   \nstd     5186.837212       1.237033    13.593407   \nmin    30158.000000    2014.000000     0.000000   \n25%    40876.000000    2016.000000     1.000000   \n50%    43504.000000    2017.000000     1.000000   \n75%    45747.000000    2018.000000     2.000000   \nmax    51592.000000    2019.000000   750.000000   \n\n       Minimum Estimated Number of Missing  Total Dead and Missing  \\\ncount                           503.000000             5333.000000   \nmean                             29.119284                5.916370   \nstd                              67.913216               28.051811   \nmin                               0.000000                0.000000   \n25%                               2.000000                1.000000   \n50%                               7.000000                1.000000   \n75%                              25.000000                3.000000   \nmax                             750.000000             1022.000000   \n\n       Number of Survivors  Number of Females  Number of Males  \\\ncount           749.000000         897.000000      2813.000000   \nmean             63.607477           2.012263         1.890864   \nstd             146.520155           2.990100         5.510674   \nmin               0.000000           0.000000         0.000000   \n25%               5.000000           1.000000         1.000000   \n50%              15.000000           1.000000         1.000000   \n75%              61.000000           2.000000         1.000000   \nmax            1950.000000          30.000000       135.000000   \n\n       Number of Children  Source Quality  \ncount          644.000000     5333.000000  \nmean             2.476708        2.895556  \nstd             10.216220        1.423257  \nmin              0.000000        1.000000  \n25%              1.000000        2.000000  \n50%              1.000000        2.000000  \n75%              2.000000        4.000000  \nmax            250.000000        5.000000  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Verifique as informações importantes dos atributos do dataframe do titanic\"\"\"\n",
    "\n",
    "\n",
    "titanic.head()\n",
    "\n",
    "titanic.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "HtrN09a3G2cX",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Observe que, apesar de o DataFrame possuir 891 registros, a coluna *idade* retorna uma quantidade de 714 registros. Isso pode ocorrer devido à presença de valores nulos/inválidos no conjunto de dados. No caso do Titanic, pode ser que a idade de certos passageiros fosse desconhecida ou não tenha sido recuperada.\n",
    "\n",
    "Dados faltantes ou incorretos acontecem com bastante frequência, e é nossa tarefa tratá-los da forma correta. Aqui, vamos definir a idade dos passageiros que estão faltando com o valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Idade'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Idade'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e93f3067a813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtitanic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Idade'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'9'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Idade'"
     ]
    }
   ],
   "source": [
    "\"\"\"Substitua os valores nulos de Idade por zero e verifique novamente as estatísticas para o DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic = titanic.update(titanic['Idade'].fillna('9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados da coluna Idade do DataFrame. Logo após, utilize o comando plt.show() \n",
    "para exibir a figura sem saídas de texto antes. \n",
    "    Dica: o pandas possui uma função que ajuda bastante nessa tarefa. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "hDaPrcMzG2cm",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Podemos querer normalizar atributos para oberservá-los em um intervalo de valores mais bem controlado. Vamos então normalizar o valor da coluna Tarifa no intervalo $[0,1]$ utilizando a normalização **min-max**, que é dada pela **fórmula**:\n",
    "\n",
    "$$v' = \\frac{v-min_A}{max_A - min_A}(nmax_A - nmin_A) + nmin_A$$\n",
    "\n",
    "onde:\n",
    "* $[nmin_A, nmax_A]$ é o intervalo no qual você deseja normalizar seus dados (no nosso caso, $[0,1]$)\n",
    "* $min_A$ e $max_A$ são os atuais valores mínimo e máximo da coluna, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeNorm' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Salve os valores máximo e mínimo da coluna em variáveis antes de efetuar a transformação.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados normalizados da coluna Idade do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PznhbJC4G2c3"
   },
   "source": [
    "Outra técnica importante é a **discretização** dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeDisc' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Para pessoas entre 0 e 17 anos, atribua o valor 'Criança'.\n",
    "    Para pessoas entre 18 e 59 anos, atribua o valor 'Adulto'.\n",
    "    Para pessoas entre 60 e 80 anos, atribua o valor 'Idoso'.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plote um histograma com os dados discretizados da coluna IdadeDisc do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \n",
    "    Dica: confira a função value_counts() do pandas.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "er9arVUSG2dB",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Após a discretização dos dados, podemos fazer o processo de **binarização**, isto é, criar uma coluna para cada categoria que contém os valores 0 ou 1 que indicam se cada linha pertence ou não a esta categoria. Isso é importante pois a grande maioria dos algoritmos e funções dos pacotes do Python não aceitam dados categóricos, sendo necessário discretizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Para cada uma das categorias criadas anteriormente (Criança, Adulto e Idoso), crie uma nova coluna\n",
    "que indicará se a linha faz parte da categoria (recebendo o valor 1) ou não (valor 0). \n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2YbzS39WG2dF",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Parte 2 - Iris\n",
    "\n",
    "Nesta parte, vamos utilizar dados sobre a classificação de plantas *Iris* a partir de suas características.\n",
    "\n",
    "Descrição dos Dados: http://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "Os dados estarão disponíveis no arquivo **iris.csv**\n",
    "\n",
    "Para este exercícios utilizaremos a biblioteca **pandas** para a leitura e manipulação dos dados. Para o trabalho de redução de dimensionalidade com **PCA** utilizaremos a implementação disponibilizada pelo <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">Scikit-Learn</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "n_pS5YSUG2dH",
    "nbgrader": {
     "checksum": "815dda85265870382dac997f48c79f98",
     "grade": false,
     "grade_id": "RO_leitura_dados",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Como este é nosso primeiro contato com a base **iris**, é importante conhecermos sua estrutura e quais as informações presentes. Ao trabalharmos com DataFrames pandas podemos utilizar a função **head()** para termos uma visão de como o arquivo está configurado, exibindo por default as 5 primeiras linhas do DataFrame.\n",
    "\n",
    "**Obs.**: a função **head()** pode receber como parâmetro o nº de linhas a ser exibido, caso queiramos ver as 10 primeiras linhas do DataFrame basta utilizarmos **head(10)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável data e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "mIS8JoiIG2dP",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "O **PCA** (Principal Component Analysis), método de redução de dimensionalidade que utilizaremos mais adiante, deve ser aplicado apenas em dados numéricos. Portanto, devemos ter certeza de que todas as colunas do nosso dataframe satisfazem a este requisito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Verifique o tipo dos dados de cada coluna do dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2yJ9qJnkG2dW",
    "nbgrader": {
     "checksum": "5b7bf63077b8d6eb675dd81e5614da5e",
     "grade": false,
     "grade_id": "RO_drop_coluna",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A princípio a coluna **species** não será necessária, devemos então salvá-la em uma nova variável e depois dropá-la de nosso dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Crie uma nova variável chamada species que receba os dados contidos na coluna 'species' de seu Dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "pMSC2SlHG2de",
    "nbgrader": {
     "checksum": "85e461ad93c30e755a09a2246aa29731",
     "grade": false,
     "grade_id": "cell-05ebff8e1ce4a432",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora já podemos dropá-la do nosso DataFrame. Para isto utilizaremos a função **drop(columns = , axis = , inplace = )**.\n",
    "\n",
    "**columns:** recebe a lista de colunas a serem dropadas.\n",
    "\n",
    "**axis:** indica em qual eixo o drop será realizado, <b>1</b> para colunas e **0** para linhas\n",
    "\n",
    "**inplace:** quando **True** a operação não gera nenhum retorno, sendo realizada na própria variável. Quando **False** (default) a alteração é efetuada apenas no retorno, precisando ser salva em alguma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Crie uma variável df onde a mesma receba o retorno da função drop descrita acima. \n",
    "Em seguida realize a operação de forma implícita, gerando ao final 2 dataframes iguais.\"\"\"\n",
    "df = data.drop('species', axis = 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Verifica se os dois dataframes possuem as mesmas colunas\"\"\"\n",
    "assert data.columns.all() == df.columns.all()\n",
    "\n",
    "\"\"\"Deletamos a variável df pois ela não será mais utilizada.\"\"\"\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "9NkSFBCHG2do",
    "nbgrader": {
     "checksum": "d212d3695e107ac115a0cb9acf27c6a8",
     "grade": false,
     "grade_id": "RO_correlacao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ok, agora que já sabemos que nossos dados são numéricos, podemos olhar para a correlação entre as colunas. Podemos fazer isso de duas formas, olhando para sua matriz de correlação e/ou plotando sua matriz de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Para gerar a matriz de correlação de um DataFrame basta utilizar a função .corr()\"\"\"\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "u0_-q6b_G2d0",
    "nbgrader": {
     "checksum": "37cf0e835c7359e9843fdc9423a256a7",
     "grade": false,
     "grade_id": "RO_matriz_dispersao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando começamos a trabalhar com uma biblioteca, é de grande importância que saibamos utilizar sua documentação como auxílio. Clique <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.plotting.scatter_matrix.html\">aqui</a> para acessar a documentação do **scatter_matrix** e gerar a matriz de dispersão dos seus dados. A imagem deverá ter tamanho (10,10) e apresentar em sua diagonal a estimativa de densidade do kernel.\n",
    "\n",
    "**Dica 1:** não se esqueça de utilizar a função plt.show() ao final da célula para que o plot seja gerado de forma limpa (sem gerar retornos em texto da função).\n",
    "\n",
    "**Dica 2:** alterne o valor do parâmetro alpha para obter uma melhor visualização dos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "cEXOD8AsG2d6",
    "nbgrader": {
     "checksum": "f0d8a6e6f1796dd2b93de6fdf2ab1045",
     "grade": false,
     "grade_id": "RO_title_pca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Utilizando o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "LP3fyAuVG2d7",
    "nbgrader": {
     "checksum": "58be7fbbf54be4d7a1fd90c353fc1b4e",
     "grade": false,
     "grade_id": "RO_pca_1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora vamos utilizar o PCA para reduzir a dimensionalidade dos nossos dados. Não se preocupe em saber os detalhes do PCA, pois vamos aprender com mais profundidade em uma próxima aula. Novamente, vamos nos guiar pela documentação da biblioteca, que você pode acessar clicando <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">aqui</a>.\n",
    "\n",
    "Em um primeiro momento, não devemos passar nenhum valor para o parâmetro **n_components**, dessa forma, podemos visualizar todos os componentes principais gerados e posteriormente decidirmos o número de componentes a serem utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Crie uma variável pca que receba a função PCA(), em seguida treine o modelo com seus dados \n",
    "e analise a porcentagem de variância explicada por cada componente principal.\n",
    "Dica: arrays possuem a função .cumsum() que permite visualizar o valor acumulativos de seus itens.\"\"\"\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pca.n_components_ == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Vw551HgEG2eG",
    "nbgrader": {
     "checksum": "50a768a6db2a278a577b60679bffe540",
     "grade": false,
     "grade_id": "RO_pca_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Baseando-se na análise realizada acima, já podemos reduzir a dimensionalidade de nossos dados. Agora o parâmetro **n_components** deve ser alterado recebendo como valor o número de componentes principais necessários para explicar no mínimo 97% da variância dos dados. Após a alteração do parâmetro, o modelo deve ser retreinado e em seguida, podemos realizar a transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Crie uma nova variável chamada data_pca, a variável deverá receber os dados transformados pelo PCA,\n",
    "contendo componentes principais suficientes para explicar 97% da variância dos dados.\"\"\"\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"O número de componentes principais não pode ser 4.\"\"\"\n",
    "assert pca.n_components_ != 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Como podemos ver abaixo, após realizar a transformação dos dados, \n",
    "a biblioteca PCA nos retorna um numpy.ndarray\"\"\"\n",
    "type(data_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KAfgWq22G2eX",
    "nbgrader": {
     "checksum": "6307d8edf42e16544db5302efbfc109b",
     "grade": false,
     "grade_id": "cell-e01b9464684af39e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora que reduzimos a dimensionalidade dos dados, podemos gerar uma visualização aproximada de como os pontos estão distribuídos no espaço, utilizando a função abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gera scatter plot utilizando como coordenada os 2 primeiros componentes principais\"\"\"\n",
    "def plot_scatter(data_pca):\n",
    "    #subplot permite que montemos o plot durante o processo de iteração.\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    #Gera pontos de cores diferentes para cada espécie\n",
    "    for spec in data_pca['species'].unique():    \n",
    "        ax.scatter(data_pca[data_pca['species'] == spec]['PC1'], \n",
    "                   data_pca[data_pca['species'] == spec]['PC2'],\n",
    "                  label = spec)\n",
    "    \n",
    "    #Determina o local onde a legenda será plotada. loc = 0: canto inferior direito\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "-LMX51wlG2ej",
    "nbgrader": {
     "checksum": "91c02dedc40c59987403bc30f3e97b32",
     "grade": false,
     "grade_id": "cell-ca08065919b78c51",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A função **plot_scatter** recebe como parâmetro um DataFrame **data_pca** com 3 colunas, **PC1, PC2, species**. Você deve converter o numpy.ndarray obtido anteriormente em um DataFrame de mesma configuração para que possa utilizar a função e gerar o scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Converta a variável data_pca em um DataFrame de colunas PC1, PC2 e species\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_scatter(data_pca)\n",
    "except:\n",
    "    raise ValueError(\"O DataFrame não cumpri os requisitos necessários.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pré-processamento de dados - Exercício.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}