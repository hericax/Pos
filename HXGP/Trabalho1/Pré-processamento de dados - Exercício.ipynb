{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "PDsi3-sMG2by",
    "nbgrader": {
     "checksum": "38fd99a0752804fa58a04ee088c6b296",
     "grade": false,
     "grade_id": "localiza",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "![](unimed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "01OoJRv6G2b1",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Pré-processamento de dados\n",
    "\n",
    "Neste hands-on, queremos aplicar técnicas de pré-processamento de dados para nos auxiliar em tarefas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "qMeuqe2iG2b_",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Parte 1 - Titanic\n",
    "\n",
    "Nesta primeira parte, vamos focar principalmente nas tarefas de limpeza e transformação de dados. Vamos utilizar novamente os dados dos passageiros do Titanic que estão disponíveis no arquivo **titanic_data.csv**.\n",
    "\n",
    "Primeiro precisamos fazer a leitura do arquivo, para isso utlizaremos a função do pandas **read_csv('nome_do_arquivo.csv')**, que faz a leitura dos dados e os armazena em um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Web ID</th>\n      <th>Region of Incident</th>\n      <th>Reported Date</th>\n      <th>Reported Year</th>\n      <th>Reported Month</th>\n      <th>Number Dead</th>\n      <th>Minimum Estimated Number of Missing</th>\n      <th>Total Dead and Missing</th>\n      <th>Number of Survivors</th>\n      <th>Number of Females</th>\n      <th>Number of Males</th>\n      <th>Number of Children</th>\n      <th>Cause of Death</th>\n      <th>Location Description</th>\n      <th>Information Source</th>\n      <th>Location Coordinates</th>\n      <th>Migration Route</th>\n      <th>URL</th>\n      <th>UNSD Geographical Grouping</th>\n      <th>Source Quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>51591</td>\n      <td>Mediterranean</td>\n      <td>March 28, 2019</td>\n      <td>2019</td>\n      <td>Mar</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>36.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>Presumed drowning</td>\n      <td>Off the coast of Chios, Greece</td>\n      <td>Hellenic Coast Guard via IOM Greece</td>\n      <td>38.362368696592, 26.172509473654</td>\n      <td>Eastern Mediterranean</td>\n      <td>NaN</td>\n      <td>Uncategorized</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51588</td>\n      <td>Mediterranean</td>\n      <td>March 26, 2019</td>\n      <td>2019</td>\n      <td>Mar</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>11.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Presumed drowning</td>\n      <td>Off the coast of Ayvacık district, Çanakkale p...</td>\n      <td>Turkish Coast Guard via IOM Turkey</td>\n      <td>39.441975591614, 26.378816195919</td>\n      <td>Eastern Mediterranean</td>\n      <td>http://bit.ly/2YmiPAN</td>\n      <td>Uncategorized</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51589</td>\n      <td>Mediterranean</td>\n      <td>March 26, 2019</td>\n      <td>2019</td>\n      <td>Mar</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Presumed drowning</td>\n      <td>Body recovered on Playa del Tarajal, Ceuta, Sp...</td>\n      <td>Ceuta al día, El Pueblo de Ceuta</td>\n      <td>35.871901875921, -5.343037665842</td>\n      <td>Western Mediterranean</td>\n      <td>http://bit.ly/2uyj7qO, http://bit.ly/2uwj5zC</td>\n      <td>Uncategorized</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51590</td>\n      <td>Mediterranean</td>\n      <td>March 26, 2019</td>\n      <td>2019</td>\n      <td>Mar</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Presumed drowning</td>\n      <td>Body recovered on beach near Tetouan, Morocco ...</td>\n      <td>El Pueblo de Ceuta</td>\n      <td>35.635115912988, -5.275650103548</td>\n      <td>Western Mediterranean</td>\n      <td>http://bit.ly/2uwj5zC</td>\n      <td>Uncategorized</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>51587</td>\n      <td>Central America</td>\n      <td>March 25, 2019</td>\n      <td>2019</td>\n      <td>Mar</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Fall from train</td>\n      <td>Train tracks in Teacalco, Tlaxcala, Mexico</td>\n      <td>Megalópolis, Línea de contraste</td>\n      <td>19.334475177429, -98.069823987538</td>\n      <td>NaN</td>\n      <td>http://bit.ly/2uvDIvH, http://bit.ly/2TXAFLS</td>\n      <td>Central America</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Web ID Region of Incident   Reported Date  Reported Year Reported Month  \\\n0   51591      Mediterranean  March 28, 2019           2019            Mar   \n1   51588      Mediterranean  March 26, 2019           2019            Mar   \n2   51589      Mediterranean  March 26, 2019           2019            Mar   \n3   51590      Mediterranean  March 26, 2019           2019            Mar   \n4   51587    Central America  March 25, 2019           2019            Mar   \n\n   Number Dead  Minimum Estimated Number of Missing  Total Dead and Missing  \\\n0          NaN                                  2.0                       2   \n1          4.0                                  NaN                       4   \n2          1.0                                  NaN                       1   \n3          1.0                                  NaN                       1   \n4          1.0                                  NaN                       1   \n\n   Number of Survivors  Number of Females  Number of Males  \\\n0                 36.0                NaN              2.0   \n1                 11.0                3.0              NaN   \n2                  NaN                NaN              NaN   \n3                  NaN                NaN              NaN   \n4                  NaN                NaN              1.0   \n\n   Number of Children     Cause of Death  \\\n0                 NaN  Presumed drowning   \n1                 1.0  Presumed drowning   \n2                 NaN  Presumed drowning   \n3                 NaN  Presumed drowning   \n4                 NaN    Fall from train   \n\n                                Location Description  \\\n0                     Off the coast of Chios, Greece   \n1  Off the coast of Ayvacık district, Çanakkale p...   \n2  Body recovered on Playa del Tarajal, Ceuta, Sp...   \n3  Body recovered on beach near Tetouan, Morocco ...   \n4         Train tracks in Teacalco, Tlaxcala, Mexico   \n\n                    Information Source               Location Coordinates  \\\n0  Hellenic Coast Guard via IOM Greece   38.362368696592, 26.172509473654   \n1   Turkish Coast Guard via IOM Turkey   39.441975591614, 26.378816195919   \n2     Ceuta al día, El Pueblo de Ceuta   35.871901875921, -5.343037665842   \n3                   El Pueblo de Ceuta   35.635115912988, -5.275650103548   \n4      Megalópolis, Línea de contraste  19.334475177429, -98.069823987538   \n\n         Migration Route                                           URL  \\\n0  Eastern Mediterranean                                           NaN   \n1  Eastern Mediterranean                         http://bit.ly/2YmiPAN   \n2  Western Mediterranean  http://bit.ly/2uyj7qO, http://bit.ly/2uwj5zC   \n3  Western Mediterranean                         http://bit.ly/2uwj5zC   \n4                    NaN  http://bit.ly/2uvDIvH, http://bit.ly/2TXAFLS   \n\n  UNSD Geographical Grouping  Source Quality  \n0              Uncategorized               5  \n1              Uncategorized               5  \n2              Uncategorized               3  \n3              Uncategorized               1  \n4            Central America               3  "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável titanic e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic = pd.read_csv(\"Trabalho1/missing-migrants/MissingMigrants-Global.csv\")\n",
    "# NÃO titanic = pd.read_csv(\"Trabalho1/googleplaystore_user_reviews.csv\")\n",
    "titanic.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Renomeie as colunas do DataFrame para facilitar o entendimento\"\"\"\n",
    "\n",
    "titanic.columns = ['IdPassageiro','Sobreviveu?','Classe','Nome','Sexo','Idade','Irmãos/Cônjuge','Pais/Crianças','Bilhete','Tarifa','Cabine','Embarque']\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Web ID                                   int64\nRegion of Incident                      object\nReported Date                           object\nReported Year                            int64\nReported Month                          object\nNumber Dead                            float64\nMinimum Estimated Number of Missing    float64\nTotal Dead and Missing                   int64\nNumber of Survivors                    float64\nNumber of Females                      float64\nNumber of Males                        float64\nNumber of Children                     float64\nCause of Death                          object\nLocation Description                    object\nInformation Source                      object\nLocation Coordinates                    object\nMigration Route                         object\nURL                                     object\nUNSD Geographical Grouping              object\nSource Quality                           int64\ndtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Verifique os tipos de cada coluna do dataframe com o auxilio do atributo dtypes\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Remova as colunas IdPassageiro, Bilhete e Cabine do DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic.drop(0).head()\n",
    "titanic.drop(8).head()\n",
    "titanic.drop(10).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "OZA0IfXRG2cQ",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando estamos trabalhando com dados, é importante saber algumas informações importantes sobre eles. Por exemplo, valores máximo e mínimo de cada atributo, sua média, desvio padrão, dentre outras. A função `describe` do pandas nos ajuda com essa tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Web ID</th>\n      <th>Reported Year</th>\n      <th>Number Dead</th>\n      <th>Minimum Estimated Number of Missing</th>\n      <th>Total Dead and Missing</th>\n      <th>Number of Survivors</th>\n      <th>Number of Females</th>\n      <th>Number of Males</th>\n      <th>Number of Children</th>\n      <th>Source Quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5333.000000</td>\n      <td>5333.000000</td>\n      <td>5142.000000</td>\n      <td>503.000000</td>\n      <td>5333.000000</td>\n      <td>749.000000</td>\n      <td>897.000000</td>\n      <td>2813.000000</td>\n      <td>644.000000</td>\n      <td>5333.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43247.885805</td>\n      <td>2016.656104</td>\n      <td>3.287631</td>\n      <td>29.119284</td>\n      <td>5.916370</td>\n      <td>63.607477</td>\n      <td>2.012263</td>\n      <td>1.890864</td>\n      <td>2.476708</td>\n      <td>2.895556</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5186.837212</td>\n      <td>1.237033</td>\n      <td>13.593407</td>\n      <td>67.913216</td>\n      <td>28.051811</td>\n      <td>146.520155</td>\n      <td>2.990100</td>\n      <td>5.510674</td>\n      <td>10.216220</td>\n      <td>1.423257</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>30158.000000</td>\n      <td>2014.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40876.000000</td>\n      <td>2016.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>43504.000000</td>\n      <td>2017.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>45747.000000</td>\n      <td>2018.000000</td>\n      <td>2.000000</td>\n      <td>25.000000</td>\n      <td>3.000000</td>\n      <td>61.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>51592.000000</td>\n      <td>2019.000000</td>\n      <td>750.000000</td>\n      <td>750.000000</td>\n      <td>1022.000000</td>\n      <td>1950.000000</td>\n      <td>30.000000</td>\n      <td>135.000000</td>\n      <td>250.000000</td>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             Web ID  Reported Year  Number Dead  \\\ncount   5333.000000    5333.000000  5142.000000   \nmean   43247.885805    2016.656104     3.287631   \nstd     5186.837212       1.237033    13.593407   \nmin    30158.000000    2014.000000     0.000000   \n25%    40876.000000    2016.000000     1.000000   \n50%    43504.000000    2017.000000     1.000000   \n75%    45747.000000    2018.000000     2.000000   \nmax    51592.000000    2019.000000   750.000000   \n\n       Minimum Estimated Number of Missing  Total Dead and Missing  \\\ncount                           503.000000             5333.000000   \nmean                             29.119284                5.916370   \nstd                              67.913216               28.051811   \nmin                               0.000000                0.000000   \n25%                               2.000000                1.000000   \n50%                               7.000000                1.000000   \n75%                              25.000000                3.000000   \nmax                             750.000000             1022.000000   \n\n       Number of Survivors  Number of Females  Number of Males  \\\ncount           749.000000         897.000000      2813.000000   \nmean             63.607477           2.012263         1.890864   \nstd             146.520155           2.990100         5.510674   \nmin               0.000000           0.000000         0.000000   \n25%               5.000000           1.000000         1.000000   \n50%              15.000000           1.000000         1.000000   \n75%              61.000000           2.000000         1.000000   \nmax            1950.000000          30.000000       135.000000   \n\n       Number of Children  Source Quality  \ncount          644.000000     5333.000000  \nmean             2.476708        2.895556  \nstd             10.216220        1.423257  \nmin              0.000000        1.000000  \n25%              1.000000        2.000000  \n50%              1.000000        2.000000  \n75%              2.000000        4.000000  \nmax            250.000000        5.000000  "
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Verifique as informações importantes dos atributos do dataframe do titanic\"\"\"\n",
    "\n",
    "titanic.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "HtrN09a3G2cX",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Observe que, apesar de o DataFrame possuir 891 registros, a coluna *idade* retorna uma quantidade de 714 registros. Isso pode ocorrer devido à presença de valores nulos/inválidos no conjunto de dados. No caso do Titanic, pode ser que a idade de certos passageiros fosse desconhecida ou não tenha sido recuperada.\n",
    "\n",
    "Dados faltantes ou incorretos acontecem com bastante frequência, e é nossa tarefa tratá-los da forma correta. Aqui, vamos definir a idade dos passageiros que estão faltando com o valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Substitua os valores nulos de Idade por zero e verifique novamente as estatísticas para o DataFrame\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "titanic = titanic.update(titanic['Idade'].fillna('9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\" Plote um histograma com os dados da coluna Idade do DataFrame. Logo após, utilize o comando plt.show() \n",
    "para exibir a figura sem saídas de texto antes. \n",
    "    Dica: o pandas possui uma função que ajuda bastante nessa tarefa. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "hDaPrcMzG2cm",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Podemos querer normalizar atributos para oberservá-los em um intervalo de valores mais bem controlado. Vamos então normalizar o valor da coluna Tarifa no intervalo $[0,1]$ utilizando a normalização **min-max**, que é dada pela **fórmula**:\n",
    "\n",
    "$$v' = \\frac{v-min_A}{max_A - min_A}(nmax_A - nmin_A) + nmin_A$$\n",
    "\n",
    "onde:\n",
    "* $[nmin_A, nmax_A]$ é o intervalo no qual você deseja normalizar seus dados (no nosso caso, $[0,1]$)\n",
    "* $min_A$ e $max_A$ são os atuais valores mínimo e máximo da coluna, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeNorm' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Salve os valores máximo e mínimo da coluna em variáveis antes de efetuar a transformação.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\" Plote um histograma com os dados normalizados da coluna Idade do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PznhbJC4G2c3"
   },
   "source": [
    "Outra técnica importante é a **discretização** dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\" Crie uma nova coluna 'IdadeDisc' no DataFrame com os valores normalizados da coluna Idade \n",
    "aplicando a fórmula descrita acima. \n",
    "    Para pessoas entre 0 e 17 anos, atribua o valor 'Criança'.\n",
    "    Para pessoas entre 18 e 59 anos, atribua o valor 'Adulto'.\n",
    "    Para pessoas entre 60 e 80 anos, atribua o valor 'Idoso'.\n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\" Plote um histograma com os dados discretizados da coluna IdadeDisc do DataFrame. \n",
    "Logo após, utilize o comando plt.show() para exibir a figura sem saídas de texto antes. \n",
    "    Dica: confira a função value_counts() do pandas.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "er9arVUSG2dB",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Após a discretização dos dados, podemos fazer o processo de **binarização**, isto é, criar uma coluna para cada categoria que contém os valores 0 ou 1 que indicam se cada linha pertence ou não a esta categoria. Isso é importante pois a grande maioria dos algoritmos e funções dos pacotes do Python não aceitam dados categóricos, sendo necessário discretizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Para cada uma das categorias criadas anteriormente (Criança, Adulto e Idoso), crie uma nova coluna\n",
    "que indicará se a linha faz parte da categoria (recebendo o valor 1) ou não (valor 0). \n",
    "    Mostre as primeiras linhas do dataframe para verificar o resultado.\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2YbzS39WG2dF",
    "nbgrader": {
     "checksum": "005083f0bfe95d203de6d572addb3a5b",
     "grade": false,
     "grade_id": "cell-12a4aeb4be7a5967",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Parte 2 - Iris\n",
    "\n",
    "Nesta parte, vamos utilizar dados sobre a classificação de plantas *Iris* a partir de suas características.\n",
    "\n",
    "Descrição dos Dados: http://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "Os dados estarão disponíveis no arquivo **iris.csv**\n",
    "\n",
    "Para este exercícios utilizaremos a biblioteca **pandas** para a leitura e manipulação dos dados. Para o trabalho de redução de dimensionalidade com **PCA** utilizaremos a implementação disponibilizada pelo <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">Scikit-Learn</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "n_pS5YSUG2dH",
    "nbgrader": {
     "checksum": "815dda85265870382dac997f48c79f98",
     "grade": false,
     "grade_id": "RO_leitura_dados",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Como este é nosso primeiro contato com a base **iris**, é importante conhecermos sua estrutura e quais as informações presentes. Ao trabalharmos com DataFrames pandas podemos utilizar a função **head()** para termos uma visão de como o arquivo está configurado, exibindo por default as 5 primeiras linhas do DataFrame.\n",
    "\n",
    "**Obs.**: a função **head()** pode receber como parâmetro o nº de linhas a ser exibido, caso queiramos ver as 10 primeiras linhas do DataFrame basta utilizarmos **head(10)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Faça a leitura do arquivo salvando seu conteúdo na variável data e depois visualize suas 5 primeiras linhas\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "mIS8JoiIG2dP",
    "nbgrader": {
     "checksum": "7394abfef286a14f0028e27029cdddc7",
     "grade": false,
     "grade_id": "cell-6f19b61b28f97b3d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "O **PCA** (Principal Component Analysis), método de redução de dimensionalidade que utilizaremos mais adiante, deve ser aplicado apenas em dados numéricos. Portanto, devemos ter certeza de que todas as colunas do nosso dataframe satisfazem a este requisito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Verifique o tipo dos dados de cada coluna do dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2yJ9qJnkG2dW",
    "nbgrader": {
     "checksum": "5b7bf63077b8d6eb675dd81e5614da5e",
     "grade": false,
     "grade_id": "RO_drop_coluna",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A princípio a coluna **species** não será necessária, devemos então salvá-la em uma nova variável e depois dropá-la de nosso dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Crie uma nova variável chamada species que receba os dados contidos na coluna 'species' de seu Dataframe\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "pMSC2SlHG2de",
    "nbgrader": {
     "checksum": "85e461ad93c30e755a09a2246aa29731",
     "grade": false,
     "grade_id": "cell-05ebff8e1ce4a432",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora já podemos dropá-la do nosso DataFrame. Para isto utilizaremos a função **drop(columns = , axis = , inplace = )**.\n",
    "\n",
    "**columns:** recebe a lista de colunas a serem dropadas.\n",
    "\n",
    "**axis:** indica em qual eixo o drop será realizado, <b>1</b> para colunas e **0** para linhas\n",
    "\n",
    "**inplace:** quando **True** a operação não gera nenhum retorno, sendo realizada na própria variável. Quando **False** (default) a alteração é efetuada apenas no retorno, precisando ser salva em alguma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Crie uma variável df onde a mesma receba o retorno da função drop descrita acima. \n",
    "Em seguida realize a operação de forma implícita, gerando ao final 2 dataframes iguais.\"\"\"\n",
    "df = data.drop('species', axis = 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Verifica se os dois dataframes possuem as mesmas colunas\"\"\"\n",
    "assert data.columns.all() == df.columns.all()\n",
    "\n",
    "\"\"\"Deletamos a variável df pois ela não será mais utilizada.\"\"\"\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "9NkSFBCHG2do",
    "nbgrader": {
     "checksum": "d212d3695e107ac115a0cb9acf27c6a8",
     "grade": false,
     "grade_id": "RO_correlacao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ok, agora que já sabemos que nossos dados são numéricos, podemos olhar para a correlação entre as colunas. Podemos fazer isso de duas formas, olhando para sua matriz de correlação e/ou plotando sua matriz de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Para gerar a matriz de correlação de um DataFrame basta utilizar a função .corr()\"\"\"\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "u0_-q6b_G2d0",
    "nbgrader": {
     "checksum": "37cf0e835c7359e9843fdc9423a256a7",
     "grade": false,
     "grade_id": "RO_matriz_dispersao",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Quando começamos a trabalhar com uma biblioteca, é de grande importância que saibamos utilizar sua documentação como auxílio. Clique <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.plotting.scatter_matrix.html\">aqui</a> para acessar a documentação do **scatter_matrix** e gerar a matriz de dispersão dos seus dados. A imagem deverá ter tamanho (10,10) e apresentar em sua diagonal a estimativa de densidade do kernel.\n",
    "\n",
    "**Dica 1:** não se esqueça de utilizar a função plt.show() ao final da célula para que o plot seja gerado de forma limpa (sem gerar retornos em texto da função).\n",
    "\n",
    "**Dica 2:** alterne o valor do parâmetro alpha para obter uma melhor visualização dos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "cEXOD8AsG2d6",
    "nbgrader": {
     "checksum": "f0d8a6e6f1796dd2b93de6fdf2ab1045",
     "grade": false,
     "grade_id": "RO_title_pca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Utilizando o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "LP3fyAuVG2d7",
    "nbgrader": {
     "checksum": "58be7fbbf54be4d7a1fd90c353fc1b4e",
     "grade": false,
     "grade_id": "RO_pca_1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora vamos utilizar o PCA para reduzir a dimensionalidade dos nossos dados. Não se preocupe em saber os detalhes do PCA, pois vamos aprender com mais profundidade em uma próxima aula. Novamente, vamos nos guiar pela documentação da biblioteca, que você pode acessar clicando <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">aqui</a>.\n",
    "\n",
    "Em um primeiro momento, não devemos passar nenhum valor para o parâmetro **n_components**, dessa forma, podemos visualizar todos os componentes principais gerados e posteriormente decidirmos o número de componentes a serem utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Crie uma variável pca que receba a função PCA(), em seguida treine o modelo com seus dados \n",
    "e analise a porcentagem de variância explicada por cada componente principal.\n",
    "Dica: arrays possuem a função .cumsum() que permite visualizar o valor acumulativos de seus itens.\"\"\"\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "assert pca.n_components_ == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Vw551HgEG2eG",
    "nbgrader": {
     "checksum": "50a768a6db2a278a577b60679bffe540",
     "grade": false,
     "grade_id": "RO_pca_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Baseando-se na análise realizada acima, já podemos reduzir a dimensionalidade de nossos dados. Agora o parâmetro **n_components** deve ser alterado recebendo como valor o número de componentes principais necessários para explicar no mínimo 97% da variância dos dados. Após a alteração do parâmetro, o modelo deve ser retreinado e em seguida, podemos realizar a transformação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Crie uma nova variável chamada data_pca, a variável deverá receber os dados transformados pelo PCA,\n",
    "contendo componentes principais suficientes para explicar 97% da variância dos dados.\"\"\"\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"O número de componentes principais não pode ser 4.\"\"\"\n",
    "assert pca.n_components_ != 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Como podemos ver abaixo, após realizar a transformação dos dados, \n",
    "a biblioteca PCA nos retorna um numpy.ndarray\"\"\"\n",
    "type(data_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "KAfgWq22G2eX",
    "nbgrader": {
     "checksum": "6307d8edf42e16544db5302efbfc109b",
     "grade": false,
     "grade_id": "cell-e01b9464684af39e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Agora que reduzimos a dimensionalidade dos dados, podemos gerar uma visualização aproximada de como os pontos estão distribuídos no espaço, utilizando a função abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Gera scatter plot utilizando como coordenada os 2 primeiros componentes principais\"\"\"\n",
    "def plot_scatter(data_pca):\n",
    "    #subplot permite que montemos o plot durante o processo de iteração.\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    #Gera pontos de cores diferentes para cada espécie\n",
    "    for spec in data_pca['species'].unique():    \n",
    "        ax.scatter(data_pca[data_pca['species'] == spec]['PC1'], \n",
    "                   data_pca[data_pca['species'] == spec]['PC2'],\n",
    "                  label = spec)\n",
    "    \n",
    "    #Determina o local onde a legenda será plotada. loc = 0: canto inferior direito\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "-LMX51wlG2ej",
    "nbgrader": {
     "checksum": "91c02dedc40c59987403bc30f3e97b32",
     "grade": false,
     "grade_id": "cell-ca08065919b78c51",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A função **plot_scatter** recebe como parâmetro um DataFrame **data_pca** com 3 colunas, **PC1, PC2, species**. Você deve converter o numpy.ndarray obtido anteriormente em um DataFrame de mesma configuração para que possa utilizar a função e gerar o scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"Converta a variável data_pca em um DataFrame de colunas PC1, PC2 e species\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter notebook failed to launch. \r\nError: The Jupyter notebook server failed to launch in time",
     "output_type": "error"
    }
   ],
   "source": [
    "try:\n",
    "    plot_scatter(data_pca)\n",
    "except:\n",
    "    raise ValueError(\"O DataFrame não cumpri os requisitos necessários.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pré-processamento de dados - Exercício.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}