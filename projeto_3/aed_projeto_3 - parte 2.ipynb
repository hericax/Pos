{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0-final"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "template original.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hericax/Pos/blob/master/projeto_3/aed_projeto_3(colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PARTE 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmzfOYVlzkXy",
        "colab_type": "text"
      },
      "source": [
        "# Projeto #3 - Meu primeiro projeto de IA\n",
        "\n",
        "Antes de começar, leia as [Instruções](https://github.com/thvmm/pos-ds-ia/blob/master/projeto_3/README.md) e os [Critérios de Avaliação](https://github.com/thvmm/pos-ds-ia/blob/master/projeto_3/README.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34xuqUqUzkYk",
        "colab_type": "text"
      },
      "source": [
        "### 4) **(30%)** Análise\n",
        "\n",
        "Com seu dado pronto, é hora de fazer a parte mais legal: investigar e responder nossas hipoteses. Elas se confirmam? Em quais cenários? Existe alguma forma de perceber isso no mundo real? Dica: Abuse das técnicas de visualização.\n",
        "\n",
        "Ex: Ainda no contexto dos exemplos do item 2). Ao investigar a hipotese relacionada ao padrão de compra, percebi que em todos os meses existia uma diferença entre dia util e final de semana. Porém notei que Fevereiro possui um comportamento diferente, o que poderia explicar? Talvez o carnaval e seus feriados.\n",
        "\n",
        "Ex2: Talvez eu descubra que alguns finais de semana possuam um comportamento diferente dos dias de semana e outros não. Por que não são todos? Nessa investigação você pode acabar descobrindo que os finais de semana que são diferentes, coincidem no fato de serem os primeiros dias utéis, o que pode remeter ao fato de boa parte das empresas realizarem pagamentos nessa parte do mês."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questionamentos a serem investigados:\n",
        "\n",
        "1 - As maiores média de votos está relacionada a algum genero específico?\n",
        "\n",
        "2 - As maiores média de votos está relacionada a algum idioma original?\n",
        "\n",
        "3 - As maiores média de votos está relacionada a algum cia de produção?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": [
        "!pip install graphviz==0.9\n",
        "!pip install pydot\n",
        "!pip install seaborn==0.9.0\n",
        "\n",
        "!apt-get install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8USWpLyCzkYV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANDO BIBLIOTECAS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "#import missingno as msno #! pip install missingno\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler #z-score\n",
        "from sklearn import preprocessing # normalização MIM-MAX\n",
        "from sklearn.preprocessing import RobustScaler \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Divisão dos dados em treino e teste\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import utils\n",
        "\n",
        "import multiprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lendo arquivo no google drive\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "arquivo_base = '/content/drive/My Drive/Colab Notebooks/projeto_3/filmes/filmes_df_limpo.csv'\n",
        "df = pd.read_csv(arquivo_base)\n",
        "df.head()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lendo o arquivo localmente\n",
        "df_final = pd.read_csv(r'C:\\Users\\User\\Documents\\Herica\\pos\\GitHub\\Pos\\projeto_3\\base\\filmes_df_limpo.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MnsbqwaUzkYn"
      },
      "source": [
        "## Hipótese 1 - As maiores média de votos está relacionada a algum genero específico?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Como são várias as features de gênero, as dividi em grupo para facilitar a visualização\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['acao'].plot(kind = 'line',color='green', title='Total da acao/target por V1',grid=True, stacked=True,label='Ação')\n",
        "x['aventura'].plot(kind = 'line',color='red', title='Total da acao/target por V1',grid=True, stacked=True,label='Aventura')\n",
        "x['animacao'].plot(kind = 'line',color='blue', title='Total da acao/target por V1',grid=True, stacked=True,label='Animação')\n",
        "x['comedia'].plot(kind = 'line',color='pink', title='Total da acao/target por V1',grid=True, stacked=True,label='Comédia')\n",
        "x['crime'].plot(kind = 'line',color='magenta', title='Total da acao/target por V1',grid=True, stacked=True,label='Crime')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Gêneros\")\n",
        "plt.ylabel(\"Média Votos\")\n",
        "\n",
        "\n",
        "# Neste gráfico, percebemos que a comédia é o gênero com maior média de votos, seguido da ação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['documentario'].plot(kind = 'line',color='green', title='Total da acao/target por V1',grid=True, stacked=True,label='Documentário')\n",
        "x['drama'].plot(kind = 'line',color='red', title='Total da acao/target por V1',grid=True, stacked=True,label='Drama')\n",
        "x['familia'].plot(kind = 'line',color='blue', title='Total da acao/target por V1',grid=True, stacked=True,label='Família')\n",
        "x['fantasia'].plot(kind = 'line',color='pink', title='Total da acao/target por V1',grid=True, stacked=True,label='Fantasia')\n",
        "x['estrangeiro'].plot(kind = 'line',color='magenta', title='Total da acao/target por V1',grid=True, stacked=True,label='Estrangeiro')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Gêneros\")\n",
        "plt.ylabel(\"Média Votos\")\n",
        "\n",
        "\n",
        "# Neste gráfico, percebemos que o drama é o gênero com maior média de votos, estando os demais mais ou menos no memo nível"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['historia'].plot(kind = 'line',color='green', title='Total da acao/target por V1',grid=True, stacked=True,label='História')\n",
        "x['horror'].plot(kind = 'line',color='red', title='Total da acao/target por V1',grid=True, stacked=True,label='Horror')\n",
        "x['musical'].plot(kind = 'line',color='blue', title='Total da acao/target por V1',grid=True, stacked=True,label='Musical')\n",
        "x['misterio'].plot(kind = 'line',color='pink', title='Total da acao/target por V1',grid=True, stacked=True,label='Mistério')\n",
        "x['romance'].plot(kind = 'line',color='magenta', title='Total da acao/target por V1',grid=True, stacked=True,label='Romance')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Gêneros\")\n",
        "plt.ylabel(\"Média Votos\")\n",
        "\n",
        "\n",
        "# Neste gráfico, percebemos que o romance é o gênero com maior média de votos, segido do horror."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['ficcao_cientifica'].plot(kind = 'line',color='green', title='Total da acao/target por V1',grid=True, stacked=True,label='Ficção')\n",
        "x['filmes_tv'].plot(kind = 'line',color='red', title='Total da acao/target por V1',grid=True, stacked=True,label='Seriados')\n",
        "x['suspense'].plot(kind = 'line',color='blue', title='Total da acao/target por V1',grid=True, stacked=True,label='Suspense')\n",
        "x['gerra'].plot(kind = 'line',color='pink', title='Total da acao/target por V1',grid=True, stacked=True,label='Gerra')\n",
        "x['ocidental'].plot(kind = 'line',color='magenta', title='Total da acao/target por V1',grid=True, stacked=True,label='Ocidental')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Gêneros\")\n",
        "plt.ylabel(\"Média Votos\")\n",
        "\n",
        "\n",
        "# Neste gráfico, percebemos que o suspense é o gênero com maior média de votos, seguido da ficção"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotando os maiores dos gêneros obtidos nos gráficos acima: comédia, suspense, romance e drama\n",
        "\n",
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['comedia'].plot(kind = 'line',color='pink',grid=True, stacked=True,label='Comédia')\n",
        "x['suspense'].plot(kind = 'line',color='blue',grid=True, stacked=True,label='Suspense')\n",
        "x['romance'].plot(kind = 'line',color='magenta',grid=True, stacked=True,label='Romance')\n",
        "x['drama'].plot(kind = 'line',color='red', grid=True, stacked=True,label='Drama')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('GÊneros x Média Votos')\n",
        "plt.xlabel(\"Gêneros\")\n",
        "plt.ylabel(\"Média Votos\")\n",
        "\n",
        "\n",
        "# Neste gráfico, percebemos que o drama é o gênero com maior média de votos, seguido da comédia. Os demais estão parecidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conforme observamos, o gênero que possui a maior média de votos é o Drama, seja isolado, seja em conjunto com outros gêneros. Dos 10 maiores, o Drama está presente em 6. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hipótese 2 - As maiores média de votos está relacionada a algum idioma original?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lingua = df_final[['lingua','media_votos']].groupby('lingua').sum().sort_values(by = 'media_votos', ascending = False).head(10)\n",
        "lingua"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotando os 10 idiomas originais com maior média de votos\n",
        "x = df_final[['lingua','media_votos']].groupby('lingua').sum().sort_values(by = 'media_votos', ascending = False).head(10)\n",
        "x = x.reset_index()\n",
        "\n",
        "plt.bar(x.lingua,x.media_votos,color='red')\n",
        "\n",
        "\n",
        "plt.xticks(rotation=75)\n",
        "plt.xlabel(\"Lingua original\")\n",
        "plt.ylabel(\"Média de votos\")\n",
        "plt.title(\"Lingua x média de votos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_ingles = len(df_final[df_final['lingua'] == \"Inglês\"])\n",
        "\n",
        "outras_linguas = ['Francês', 'Chines', 'Italiano', 'Persa', 'Neerlandês',\n",
        "       'Alemão', 'Mandarim padrão', 'Argentino', 'Espanhol', 'Russo',\n",
        "       'Japonês', 'Coreano', 'Sérvio', 'Bengali', 'Hebraico', 'Português',\n",
        "       'Wolof', 'Romeno', 'Húngaro', 'Galês', 'Vietnamita', 'hrv',\n",
        "       'Dinamarquês', 'Norueguês', 'Bokmål norueguês', 'Polonês',\n",
        "       'Grego, Moderno', 'Shan', 'No Language', 'Macedônio', 'Tibetano',\n",
        "       'Catalão', 'Finlandês', 'Tailandês', 'Eslovaco', 'Bósnio', 'Hindi',\n",
        "       'Turco', 'Islandês', 'Pachto', 'Abecásio', 'Esperanto',\n",
        "       'Georgiano', 'Mongol', 'Bambara', 'Zulu', 'Ucraniano', 'Africâner',\n",
        "       'Latim', 'Estoniano', 'Curdo', 'Letão', 'Tâmil', 'Esloveno',\n",
        "       'Tagalog', 'Urdu', 'Kinyarwanda', 'Indonésio', 'Búlgaro',\n",
        "       'Marathi (Marāṭhī)', 'Lituano', 'Cazaque', 'Malaio', 'Albanês',\n",
        "       'Quechua', 'Telugu', 'Amárico', 'Javanês', 'Tajique', 'Malayalam',\n",
        "       'Croata', 'Lao', 'Aymará', 'Canarês', 'Nepali', 'Panjabi, Punjabi',\n",
        "       'Galego', 'Quirguiz, Kyrgyz', 'Samoano', 'Basco', 'Tcheco',\n",
        "       'Armênio', 'Inuktitut', 'Sinhala, Cingalês']\n",
        "total_outras = 0\n",
        "for i in outras_linguas:\n",
        "    total_outras = total_outras + len(df_final[df_final['lingua'] == i])\n",
        "\n",
        "total_linguas = total_outras + total_ingles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('total_outras=',total_outras, 'total_ingles=', total_ingles, '\\n Total linguas', total_linguas, '\\n diferença ingles - outras= ', total_ingles - total_outras, '\\n registros dataset=', len(df_final.lingua))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print (\"Ingles=\", (total_ingles/total_linguas)*100)\n",
        "print (\"Outras=\", (total_outras/total_linguas)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": [
        "Percebe-se acima que mesmo somando todas as outras linguas originais dos filmes, o inglês é o maior idioma, com 70%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hipótese 3 - As maiores média de votos está relacionada a algum cia de produção?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('MGM', len(df_final[df_final['Metro-Goldwyn-Mayer (MGM)'] == True]))\n",
        "print ('Warner', len(df_final[df_final['Warner Bros.'] == True]))\n",
        "print ('Paramount', len(df_final[df_final['Paramount Pictures'] == True]))\n",
        "print ('Fox', len(df_final[df_final['Twentieth Century Fox Film Corporation'] == True]))\n",
        "print ('Universal', len(df_final[df_final['Universal Pictures'] == True]))\n",
        "print ('RKO', len(df_final[df_final['RKO Radio Pictures'] == True]))\n",
        "print ('Columbia', len(df_final[df_final['Columbia Pictures'] == True]))\n",
        "print ('Mosfilm', len(df_final[df_final['Mosfilm'] == True]))\n",
        "print ('Walt Disney', len(df_final[df_final['Walt Disney Pictures'] == True]))\n",
        "print ('Universal International Pictures (UI)', len(df_final[df_final['Universal International Pictures (UI)'] == True]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotando os maiores dos gêneros obtidos nos gráficos acima: comédia, suspense, romance e drama\n",
        "\n",
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "x['Metro-Goldwyn-Mayer (MGM)'].plot(kind = 'line',color='pink',grid=True, stacked=True,label='MGM')\n",
        "x['Warner Bros.'].plot(kind = 'line',color='blue',grid=True, stacked=True,label='Warner Bros.')\n",
        "x['Paramount Pictures'].plot(kind = 'line',color='magenta',grid=True, stacked=True,label='Paramount Pictures')\n",
        "x['Twentieth Century Fox Film Corporation'].plot(kind = 'line',color='red', grid=True, stacked=True,label='Twentieth Century Fox Film Corporation')\n",
        "x['Universal Pictures'].plot(kind = 'line',color='yellow', grid=True, stacked=True,label='Universal Pictures')\n",
        "x['RKO Radio Pictures'].plot(kind = 'line',color='brown', grid=True, stacked=True,label='RKO Radio Pictures')\n",
        "x['Columbia Pictures'].plot(kind = 'line',color='black', grid=True, stacked=True,label='Columbia Pictures')\n",
        "x['Mosfilm'].plot(kind = 'line',color='green', grid=True, stacked=True,label='Mosfilm')\n",
        "x['Walt Disney Pictures'].plot(kind = 'line',color='purple', grid=True, stacked=True,label='Walt Disney Pictures')\n",
        "x['Universal International Pictures (UI)'].plot(kind = 'line',color='grey', grid=True, stacked=True,label='Universal International Pictures (UI)')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Companias x Média Votos')\n",
        "plt.xlabel(\"Companias\")\n",
        "plt.ylabel(\"Média Votos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# plotando os maiores dos gêneros obtidos nos gráficos acima: comédia, suspense, romance e drama\n",
        "\n",
        "# Como são várias as features de gênero, as divide\n",
        "x = df_final.groupby(['media_votos']).sum()\n",
        "\n",
        "\n",
        "x['Metro-Goldwyn-Mayer (MGM)'].plot(kind = 'bar',color='pink',grid=True, stacked=True,label='MGM')\n",
        "x['Warner Bros.'].plot(kind = 'bar',color='blue',grid=True, stacked=True,label='Warner Bros.')\n",
        "x['Paramount Pictures'].plot(kind = 'bar',color='magenta',grid=True, stacked=True,label='Paramount Pictures')\n",
        "x['Twentieth Century Fox Film Corporation'].plot(kind = 'bar',color='red', grid=True, stacked=True,label='Twentieth Century Fox Film Corporation')\n",
        "x['Universal Pictures'].plot(kind = 'bar',color='yellow', grid=True, stacked=True,label='Universal Pictures')\n",
        "x['RKO Radio Pictures'].plot(kind = 'bar',color='brown', grid=True, stacked=True,label='RKO Radio Pictures')\n",
        "x['Columbia Pictures'].plot(kind = 'bar',color='black', grid=True, stacked=True,label='Columbia Pictures')\n",
        "x['Mosfilm'].plot(kind = 'bar',color='green', grid=True, stacked=True,label='Mosfilm')\n",
        "x['Walt Disney Pictures'].plot(kind = 'bar',color='purple', grid=True, stacked=True,label='Walt Disney Pictures')\n",
        "x['Universal International Pictures (UI)'].plot(kind = 'bar',color='grey', grid=True, stacked=True,label='Universal International Pictures (UI)')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Companias x Média Votos')\n",
        "plt.xlabel(\"Companias\")\n",
        "plt.ylabel(\"Média Votos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Percebe-se que a companhia com as maiores médias de votos é a Warner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdSyCHTnzkZi",
        "colab_type": "text"
      },
      "source": [
        "### 5) Modelagem 30%\n",
        "\n",
        "Agora você terá mais uma oportunidade de mostrar o que você aprendeu durante o módulo 2 quanto a modelagem de dados e criação de modelos. Utilizando os dados preparados na seção 1 e após a análise feita na seção 2 você deverá:\n",
        "1. **Defina um problema de regressão ou classificação que envolva uma variável dos seus dados.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Será criado um modelo de regrassão para prever a média de votos dos filmes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rMt4KkrzkZl",
        "colab_type": "text"
      },
      "source": [
        "2. **Realize ao menos 2 técnicas de processamento e seleção de features.**\n",
        "    * Isto inclui, normalização, PCA, e técnicas de seleção de features como information gain. Seja criativo pois está parte é crucial para seu modelo. Você pode escolhar manualmente as features desde que seja justificada na seção 2 (parte de Análise).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DISCRETIZAÇÃO DA FEATURE DURACAO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# verificando a correlação da duração com a média de votos\n",
        "corr_ini_duracao = df_final['duracao'].corr(df_final['media_votos'])\n",
        "print ('duração x media_votos',corr_ini_duracao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.duracao.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vou tentar criar grupos para definir a feture e verificar se há melhora na correlação\n",
        "intervals = pd.qcut(df_final['duracao'], 2).astype(str).unique()\n",
        "intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final['tipo_duracao'] = pd.qcut(df_final['duracao'], 2).astype(str).map( {\n",
        "                            intervals[0]: 'media',\n",
        "                            intervals[1]: 'longa'\n",
        "                            } ).astype(str)\n",
        "df_final[['duracao','tipo_duracao']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotando os 10 idiomas originais com maior média de votos\n",
        "x = df_final[['tipo_duracao','media_votos']].groupby('tipo_duracao').sum().sort_values(by = 'media_votos', ascending = False).head(10)\n",
        "x = x.reset_index()\n",
        "\n",
        "plt.bar(x.tipo_duracao,x.media_votos,color='red')\n",
        "\n",
        "\n",
        "plt.xticks(rotation=75)\n",
        "plt.xlabel(\"Tipo de duração\")\n",
        "plt.ylabel(\"Média de votos\")\n",
        "plt.title(\"Tipo de duração x média de votos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertando strings em numéricos usando dicionário\n",
        "\n",
        "df_final['tipo_duracao'] = df_final['tipo_duracao'].map({\n",
        "'media': 0, \n",
        "'longa': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# verificando a correlação da duração com a média de votos\n",
        "corr_fim_duracao = df_final['tipo_duracao'].corr(df_final['media_votos'])\n",
        "print ('Tipo duração x media_votos',corr_fim_duracao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('Final', corr_fim_duracao, ' | inicial', corr_ini_duracao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fiz o teste da correlação para os valores de 2 a 5 grupos. Quanto maior a qtde de grupos, pior a correlação.\n",
        "Nova feature mantida pois houve uma pequena melhora na correlação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DISCRETIZAÇÃO DA FEATURE ANO_LANCAMENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# verificando a correlação da duração com a média de votos\n",
        "corr_ini_anoLancamento = df_final['ano_lancamento'].corr(df_final['media_votos'])\n",
        "print ('Ano lançamento x media_votos',corr_ini_anoLancamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tentar criar períodos para melhor a correlação\n",
        "# avaliando a quantidade de períodos a serem criados \n",
        "intervals = pd.qcut(df_final['ano_lancamento'], 10).astype(str).unique()\n",
        "intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando os perídos para definir o ano de lançamento dos filmes\n",
        "df_final['periodo'] = pd.qcut(df_final['ano_lancamento'], 10).astype(str).map({intervals[0]: '1993 a 2000',\n",
        "        intervals[1]: '1970 a 1982',\n",
        "        intervals[2]: '1982 a 1993',\n",
        "        intervals[3]: '1952 a 1970',\n",
        "        intervals[4]: '1873 a 1952',\n",
        "        intervals[5]: '2000 a 2005',\n",
        "        intervals[6]: '2009 a 2012',\n",
        "        intervals[7]: '2012 a 2014',\n",
        "        intervals[8]: '2005 a 2009',\n",
        "        intervals[9]: '2014 a 2020'} ).astype(str)\n",
        "\n",
        "df_final[['ano_lancamento','periodo']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotando os 10 idiomas originais com maior média de votos\n",
        "x = df_final[['periodo','media_votos']].groupby('periodo').sum().sort_values(by = 'media_votos', ascending = False).head(10)\n",
        "x = x.reset_index()\n",
        "\n",
        "plt.bar(x.periodo,x.media_votos,color='red')\n",
        "\n",
        "\n",
        "plt.xticks(rotation=75)\n",
        "plt.xlabel(\"Período\")\n",
        "plt.ylabel(\"Média de votos\")\n",
        "plt.title(\"Período x média de votos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertando strings em numéricos usando dicionário\n",
        "\n",
        "df_final['tipo_duracao'] = df_final['periodo'].map({\n",
        "    '1993 a 2000': 0,\n",
        "    '1970 a 1982': 1,\n",
        "    '1982 a 1993': 2,\n",
        "    '1952 a 1970': 3,\n",
        "    '1873 a 1952': 4,\n",
        "    '2000 a 2005': 5,\n",
        "    '2009 a 2012': 6,\n",
        "    '2012 a 2014': 7,\n",
        "    '2005 a 2009': 8,\n",
        "    '2014 a 2020': 9\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# verificando a correlação da duração com a média de votos\n",
        "corr_fim_anoLancamento = df_final['tipo_duracao'].corr(df_final['media_votos'])\n",
        "print ('Ano lançamento x media_votos',corr_fim_anoLancamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print (\" final= \", corr_fim_anoLancamento, \"| inicial = \",corr_ini_anoLancamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Houve melhora então a nova feature será mantida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FAZER A CORRELAÇÃO DAS FEATURES A SEREM TRABALHADAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# verificando a correlação dos generos\n",
        "\n",
        "print ('acao x media_votos',df_final['acao'].corr(df_final['media_votos']))\n",
        "print ('aventura x media_votos',df_final['aventura'].corr(df_final['media_votos']))\n",
        "print ('animacao x media_votos',df_final['animacao'].corr(df_final['media_votos']))\n",
        "print ('comedia x media_votos',df_final['comedia'].corr(df_final['media_votos']))\n",
        "print ('crime x media_votos',df_final['crime'].corr(df_final['media_votos']))\n",
        "print ('documentario x media_votos',df_final['documentario'].corr(df_final['media_votos']))\n",
        "print ('drama x media_votos',df_final['drama'].corr(df_final['media_votos']))\n",
        "print ('familia x media_votos',df_final['familia'].corr(df_final['media_votos']))\n",
        "print ('fantasia x media_votos',df_final['fantasia'].corr(df_final['media_votos']))\n",
        "print ('estrangeiro x media_votos',df_final['estrangeiro'].corr(df_final['media_votos']))\n",
        "print ('historia x media_votos',df_final['historia'].corr(df_final['media_votos']))\n",
        "print ('horror x media_votos',df_final['horror'].corr(df_final['media_votos']))\n",
        "print ('musical x media_votos',df_final['musical'].corr(df_final['media_votos']))\n",
        "print ('misterio x media_votos',df_final['misterio'].corr(df_final['media_votos']))\n",
        "print ('romance x media_votos',df_final['romance'].corr(df_final['media_votos']))\n",
        "print ('ficcao_cientifica x media_votos',df_final['ficcao_cientifica'].corr(df_final['media_votos']))\n",
        "print ('filmes_tv x media_votos',df_final['filmes_tv'].corr(df_final['media_votos']))\n",
        "print ('suspense x media_votos',df_final['suspense'].corr(df_final['media_votos']))\n",
        "print ('gerra x media_votos',df_final['gerra'].corr(df_final['media_votos']))\n",
        "print ('ocidental x media_votos',df_final['ocidental'].corr(df_final['media_votos']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Excluir as features com correlação negativa\n",
        "'''acao x media_votos -0.08289026991958133\n",
        "aventura x media_votos -0.02794159637963377\n",
        "comedia x media_votos -0.01778207543223205\n",
        "familia x media_votos -0.01386665979818757\n",
        "fantasia x media_votos -0.013615448225225833\n",
        "estrangeiro x media_votos -0.0045234706117887975\n",
        "horror x media_votos -0.18819159408147684\n",
        "misterio x media_votos -0.008024703581022141\n",
        "ficcao_cientifica x media_votos -0.11295899314774636\n",
        "filmes_tv x media_votos -0.03709269978090582\n",
        "suspense x media_votos -0.09543228084790208\n",
        "ocidental x media_votos -0.03503105661478576'''\n",
        "\n",
        "df_final.drop(['acao','aventura','comedia', 'familia', 'fantasia', 'estrangeiro', 'horror', 'misterio',\n",
        "    'ficcao_cientifica', 'filmes_tv', 'suspense', 'ocidental'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('video x media_votos',df_final['video'].corr(df_final['media_votos']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remoção da feature video\n",
        "df_final.drop(['video'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# features de companhias de produção\n",
        "''''Metro-Goldwyn-Mayer (MGM)','Warner Bros.', 'Paramount Pictures',\n",
        "       'Twentieth Century Fox Film Corporation', 'Universal Pictures',\n",
        "       'RKO Radio Pictures', 'Columbia Pictures', 'Mosfilm',\n",
        "       'Walt Disney Pictures', 'Universal International Pictures (UI)'\n",
        "       '''\n",
        "\n",
        "print ('MGV',df_final['Metro-Goldwyn-Mayer (MGM)'].corr(df_final['media_votos']))\n",
        "print ('Warner Bros. x media_votos',df_final['Warner Bros.'].corr(df_final['media_votos']))\n",
        "print ('Paramount x media_votos',df_final['Paramount Pictures'].corr(df_final['media_votos']))\n",
        "print ('Fox x media_votos',df_final['Twentieth Century Fox Film Corporation'].corr(df_final['media_votos']))\n",
        "print ('Universal Pictures x media_votos',df_final['Universal Pictures'].corr(df_final['media_votos']))\n",
        "print ('RKO Radio Pictures x media_votos',df_final['RKO Radio Pictures'].corr(df_final['media_votos']))\n",
        "print ('Columbia Pictures x media_votos',df_final['Columbia Pictures'].corr(df_final['media_votos']))\n",
        "print ('Mosfilm x media_votos',df_final['Mosfilm'].corr(df_final['media_votos']))\n",
        "print ('Walt Disney Pictures x media_votos',df_final['Walt Disney Pictures'].corr(df_final['media_votos']))\n",
        "print ('Universal International Pictures (UI) x media_votos',df_final['Universal International Pictures (UI)'].corr(df_final['media_votos']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# excluido das features com correlação negativa\n",
        "'''\n",
        "MGV -0.005643144906661703\n",
        "RKO Radio Pictures x media_votos -0.005677699693419887\n",
        "\n",
        "'''\n",
        "\n",
        "df_final.drop(['Metro-Goldwyn-Mayer (MGM)','RKO Radio Pictures'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# features de paizes onde os filmes foram produzidos\n",
        "'''\n",
        "'United States of America', 'United Kingdom', 'France', 'Japan',\n",
        "       'Italy', 'Canada', 'Canada.1', 'Canada.2', 'Canada.3', 'Germany',\n",
        "       'Russia', 'India', 'Canada.4', 'Canada.5', 'Canada.6', 'Canada.7',\n",
        "       'English', 'Français', '日本語', 'Italiano', 'Español'\n",
        "    '''\n",
        "print ('United States of America',df_final['United States of America (pais producao)'].corr(df_final['media_votos']))\n",
        "print ('United Kingdom x media_votos',df_final['United Kingdom (pais producao)'].corr(df_final['media_votos']))\n",
        "print ('France x media_votos',df_final['France (pais producao)'].corr(df_final['media_votos']))\n",
        "print ('Japan x media_votos',df_final['Japan (pais producao)'].corr(df_final['media_votos']))\n",
        "print ('Italy x media_votos',df_final['Italy (pais producao)'].corr(df_final['media_votos']))\n",
        "print ('Canada x media_votos',df_final['Canada (pais producao)'].corr(df_final['media_votos']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remoção das features com correlação negativa\n",
        "'''\n",
        "United States of America -0.10648717484568719\n",
        "Canada x media_votos -0.04293418732490301\n",
        "'''\n",
        "\n",
        "df_final.drop(['United States of America (pais producao)','Canada (pais producao)'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# correlação dos idimos de tradução\n",
        "''' 'English', 'Français', '日本語', 'Italiano', 'Español' '''\n",
        "\n",
        "print ('English x media_votos',df_final['English'].corr(df_final['media_votos']))\n",
        "print ('Français x media_votos',df_final['Français'].corr(df_final['media_votos']))\n",
        "print ('日本語 x media_votos',df_final['日本語'].corr(df_final['media_votos']))\n",
        "print ('Italiano x media_votos',df_final['Italiano'].corr(df_final['media_votos']))\n",
        "print ('Español x media_votos',df_final['Español'].corr(df_final['media_votos']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remoção das features com correlação negativa\n",
        "'''\n",
        "English x media_votos -0.1104885381792159\n",
        "'''\n",
        "\n",
        "df_final.drop(['English'], axis = 1, inplace = True)"
      ]
    },
    {
      "source": [
        "# inicio dos testes"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dividindo o target em classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dividindo em três classes\n",
        "pd.cut(df_final['media_votos'], 5).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final['target'] = pd.cut(df_final['media_votos'], 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "a = df_final.groupby('target').size()\n",
        "\n",
        "categories = df_final['target'].cat.categories\n",
        "ind = np.array([x for x, _ in enumerate(categories)])\n",
        "width = 0.35       \n",
        "plt.bar(ind, a, width, label='target')\n",
        "\n",
        "plt.xticks(ind + width / 3, categories)\n",
        "plt.legend(loc='best')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "# fim dos testes"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SELECIONANDO AS FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Selecionando as features que serão utilizadas para redução da dimensionalidade e normalização \n",
        "X = df_final[[ \n",
        "    'ano_lancamento', 'cod_lingua', 'qtde_votos', \n",
        "       'animacao', 'crime',\n",
        "       'documentario', 'drama', 'historia', 'musical', 'romance', 'gerra',\n",
        "       'Warner Bros.', 'Paramount Pictures',\n",
        "       'Twentieth Century Fox Film Corporation', 'Universal Pictures',\n",
        "       'Columbia Pictures', 'Mosfilm', 'Walt Disney Pictures',\n",
        "       'Universal International Pictures (UI)',\n",
        "       'United Kingdom (pais producao)', 'France (pais producao)',\n",
        "       'Japan (pais producao)', 'Italy (pais producao)',\n",
        "       'Canada (pais producao).1', 'Germany (pais producao)',\n",
        "       'Russia (pais producao)', 'India (pais producao)', 'Français', '日本語',\n",
        "       'Italiano', 'Español', 'tipo_duracao'\n",
        "       ]]\n",
        "       \n",
        "y = df_final['media_votos'].round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# target desbalanceados\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# guardando o rótulo das colunas\n",
        "cols = X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## REDUÇÃO DA DIMENSIONALIDADE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AVALIAR QUAL A QUANTIDADE DE COMPONENTES UTILIZAR NO pca\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "\n",
        "pca = PCA().fit(X)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='#191970')\n",
        "\n",
        "plt.title('Escolha do número de componentes', y=1.03, size=14, loc='left', x=-0.06)\n",
        "plt.ylabel('Variância explicada cumulativa', horizontalalignment='left', y=0.30)\n",
        "plt.xlabel('Número de componentes', horizontalalignment='right', x=0.265)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# APLICAR O PCA\n",
        "dados_dimensionados = PCA(n_components=3).fit_transform(X)\n",
        "\n",
        "dados_dimensionados = pd.DataFrame(dados_dimensionados)\n",
        "\n",
        "dados_dimensionados.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# APLICAR O PCA\n",
        "'''\n",
        "dados_dimensionados = PCA(n_components=3).fit_transform(X)\n",
        "dados_dimensionados\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_dimensionados.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NORMALIZAÇÃO DOS DADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NORMALIZAÇÃO MIM-MAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A normalização é feita feature a feature e o objeto é colocar as variáveis dentro do intervalo de 0 e 1\n",
        "min_max_scaler = preprocessing.MinMaxScaler() #dimensiona e traduz cada recurso individualmente, de modo que esteja no intervalo especificado no conjunto de treinamento (entre zero e um)\n",
        "x_scaled = min_max_scaler.fit_transform(X)\n",
        "df_normalizado_MIMMAX = pd.DataFrame(x_scaled)\n",
        "\n",
        "# renomeando as colunas\n",
        "df_normalizado_MIMMAX.set_axis(cols, axis='columns', inplace=True)\n",
        "df_normalizado_MIMMAX.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_normalizado_MIMMAX.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NORMALIZAÇÃO Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalizar os recursos (cada coluna dos dados) para que cada coluna/recurso/variável tenha mean = 0 e standard deviation = 1.\n",
        "scaler = StandardScaler()\n",
        "df_normalizado_scaler = scaler.fit_transform(X)\n",
        "df_normalizado_scaler = pd.DataFrame(df_normalizado_scaler)\n",
        "\n",
        "# renomeando as colunas\n",
        "df_normalizado_scaler.set_axis(cols, axis='columns', inplace=True)\n",
        "df_normalizado_scaler.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_normalizado_scaler.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df_normalizado_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RobustScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#subtrai a média do valor em questão e então divide o resultado pelo segundo quartil.\n",
        "df_nomealizado_robust = RobustScaler().fit_transform(X)\n",
        "df_nomealizado_robust = pd.DataFrame(df_nomealizado_robust)\n",
        "\n",
        "# renomeando as colunas\n",
        "df_nomealizado_robust.set_axis(cols, axis='columns', inplace=True)\n",
        "df_nomealizado_robust.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_nomealizado_robust.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_il81uyzkZ2",
        "colab_type": "text"
      },
      "source": [
        "3. **Defina uma métrica para avaliar o seu modelo.**\n",
        "    * Por exemplo, você pode utilizar MAE (Mean Absolute Error) para um problema de regressão. Ou, F1-Score para um problema de classificação. Há varias métricas, então escolha sabiamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYZyaLy_zkZ4",
        "colab_type": "text"
      },
      "source": [
        "Será utilizado como métrica o desvio padrão, que que serve para dizer o quanto os valores dos quais se extraiu a média são próximos ou distantes da própria média. Assim, quando se calcula o desvio padrão juntamente com a média de diferentes grupos, obtém-se mais informações para avaliar e diferenciar seus comportamentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP4p63QEzkZ5",
        "colab_type": "text"
      },
      "source": [
        "4. **Divida seus dados em 2 conjuntos. Um de treino e outro conjunto de teste.**\n",
        "    * Treine e otimize seu modelo no conjunto de treino e apenas use o conjunto de teste para apresentar os resultados finais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# semente aleatória a ser utilizada em tydi\n",
        "RANDOM_STATE = 1 #semente aleatória\n",
        "test_size = 0.35 # 35% será amostra de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DPxkTwo_zkZ7"
      },
      "source": [
        "Divisão dos dados - redimencionados (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# o parâmetro test_size indica o percentual de amostras que serão selecionadas para teste\n",
        "\n",
        "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(dados_dimensionados,y, \n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=RANDOM_STATE)\n",
        "                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('Quantidade de registros \\n')\n",
        "print('Dados de treino PCA: X =', X_train_PCA.shape,'y=', y_train_PCA.shape,'\\n','Dados de teste: X= ', X_test_PCA.shape,'y=', y_test_PCA.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Divisão dos dados - normalização MIM_MAx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# o parâmetro test_size indica o percentual de amostras que serão selecionadas para teste\n",
        "\n",
        "X_train_MIMMAX, X_test_MIMMAX, y_train_MIMMAX, y_test_MIMMAX = train_test_split(df_normalizado_MIMMAX, y, \n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('Quantidade de registros \\n')\n",
        "print('Dados de treino PCA: X =', X_train_MIMMAX.shape,'y=', y_train_MIMMAX.shape,'\\n','Dados de teste: X= ', X_test_MIMMAX.shape,'y=', y_test_MIMMAX.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Divisão dos dados - normalização Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# o parâmetro test_size indica o percentual de amostras que serão selecionadas para teste\n",
        "\n",
        "X_train_scaler, X_test_scaler, y_train_scaler, y_test_scaler = train_test_split(df_normalizado_scaler, y, \n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('Quantidade de registros \\n')\n",
        "print('Dados de treino PCA: X =', X_train_scaler.shape,'y=', y_train_scaler.shape,'\\n','Dados de teste: X= ', X_test_scaler.shape,'y=', y_test_scaler.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Divisão dos dados - normalização ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# o parâmetro test_size indica o percentual de amostras que serão selecionadas para teste\n",
        "\n",
        "X_train_robust, X_test_robust, y_train_robust, y_test_robust = train_test_split(df_nomealizado_robust, y, \n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print ('Quantidade de registros \\n')\n",
        "print('Dados de treino PCA: X =', X_train_robust.shape,'y=', y_train_robust.shape,'\\n','Dados de teste: X= ', X_test_robust.shape,'y=', y_test_robust.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOGZ0KOzkaF",
        "colab_type": "text"
      },
      "source": [
        "5. **Treine um ou mais modelos de ML para o seu problema.**\n",
        "    * Escolha 1 ou mais tipos de classificadores ou regressores dependendo do seu problema.\n",
        "    * Por exemplo, TreeClassifier para um problema de classificação. \n",
        "    * Use cross-validation e outras técnicas como GridSearch e ou RandomizedSearch para encontrar os melhores parametros para o seu modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# criar o DF para armazenas as métrica coletadas em cada algoritmo\n",
        "COLUNAS = [\n",
        "    'tipo_dado', # se é PCA, MIM-MAX, Scaler ou robust\n",
        "    'media_teste', \n",
        "    'media_treino',\n",
        "    'diferenca_media',\n",
        "    'desvio_teste' ,\n",
        "    'desvio_teste',\n",
        "    'diferenca_desvio'    \n",
        "]\n",
        "\n",
        "df_tree_metricas = pd.DataFrame(columns=COLUNAS)\n",
        "df_tree_metricas\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEFININDO AS FUNÇÕES QUE SERÃO UTILIZADAS PARA RODAR OS MODELOS, PLOTAR A MATRIZ DE CONFUSÃO E ARMAZENAR AS MÉTRICAS COLETADAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando do dataframe para armazenar as métricas coletadas a cada execução do modelo\n",
        "columns = ['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'] \n",
        "''''\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "metricas = pd.DataFrame(columns=columns)\n",
        "\n",
        "# função para inserir registro no dataframe\n",
        "def insert(df, row):\n",
        "    insert_loc = df.index.max()\n",
        "\n",
        "    if np.isnan(insert_loc):\n",
        "        df.loc[0] = row\n",
        "    else:\n",
        "        df.loc[insert_loc + 1] = row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "# FUNÇÃO PARA RODAR O MODELO\n",
        "def roda_modelo (tipo, nome_modelo, X_train, y_train, X_test, y_test, modelo):\n",
        "    modelo.fit(X_train, y_train) # TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "    y_pred = modelo.predict(X_test) # predizendo o target\n",
        "    \n",
        "    print (\"{} do {}\".format(tipo, nome_modelo))\n",
        "    print (\"\\n\")\n",
        "\n",
        "    classes = [0,1,2,3,4,5,6,7,8,9,10]\n",
        "    resultados = mostra_resultados(y_test, y_pred, classes,tipo, nome_modelo)\n",
        "    \n",
        "    return resultados, modelo\n",
        "\n",
        "\n",
        "# FUNÇÃO PARA PLOTAR A MATRIZ DE CONFUSÃO\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greens):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    \n",
        "    plt.grid(False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "# FUNÇÃO PARA MOSTRA RESULTADOS OBTIDOS NO MODELO\n",
        "def mostra_resultados(y, y_pred, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.coolwarm):\n",
        "\n",
        "    # Calcular os resultados\n",
        "    #cm = confusion_matrix(y, y_pred.round(0))\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)  # Falso Positivos\n",
        "    FN = cm.sum(axis=1) - np.diag(cm)  # Falso Negativos\n",
        "    TP = np.diag(cm)                   # Verdadeiro Positivo\n",
        "    TN = cm.sum() - (FP + FN + TP)     # Verdadeiro Negativos\n",
        "    TPR = TP / (TP + FN)  # Revocação    \n",
        "    PPV = TP / (TP + FP)  # Precisao\n",
        "    F1 = 2 * ((PPV * TPR) / (PPV + TPR)) # F1 Score\n",
        "    ACC = (TP + TN) / (TP + FP + FN + TN)  # Acurácia\n",
        "\n",
        "    desvio_y_test = y.std()\n",
        "    desvio_y_pred = y_pred.std()\n",
        "    diferenca_desvio = desvio_y_test - desvio_y_pred\n",
        "\n",
        "    media_y_test = y.mean()\n",
        "    media_y_prev = y_pred.mean()\n",
        "    diferenca_media = media_y_test - media_y_prev\n",
        "\n",
        "    # Exibe resultados\n",
        "    print(\"    Verdadeiros Positivos:{}\".format(TP))\n",
        "    print(\"    Verdadeiros Negativos:{}\".format(TN))\n",
        "    print(\"    Falso Positivo:{}\".format(FP))\n",
        "    print(\"    Falso Negativo:{}\".format(FN))\n",
        "    \n",
        "    print(\"    Revocação:{}\".format(TPR))    \n",
        "    print(\"    Precisao:{}\".format(PPV))\n",
        "    \n",
        "    \n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    print(\"    F1 Score:{}\".format(F1.round(4)))\n",
        "    print(\"    \\nAcuracia:{}\".format(ACC.round(4)*100))\n",
        "\n",
        "    print(\"    \\n Desvio \\n\")\n",
        "    print(\"    y_tes:{}\".format(desvio_y_test))\n",
        "    print(\"    y_pred:{}\".format(desvio_y_pred))\n",
        "    print(\"    Diferença:{}\".format(diferenca_desvio))\n",
        "    \n",
        "    print(\"    \\n Média \\n\")\n",
        "    print(\"    y_tes:{}\".format(media_y_test))\n",
        "    print(\"    y_pred:{}\".format(media_y_prev))\n",
        "    print(\"    Diferença:{}\".format(diferenca_media))\n",
        "    \n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    plot_confusion_matrix(cm, classes)\n",
        "\n",
        "    return desvio_y_test, desvio_y_pred, diferenca_desvio, media_y_test, media_y_prev, diferenca_media, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELO 1 - DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CRIAÇÃO DO MODELO COM PARÂMETROS PADRÃO\n",
        "dec_clf = DecisionTreeRegressor(random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dec_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# INICIO TESTES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_PCA_tree = roda_modelo('BASELINE DECISION TREE', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA, dec_clf)\n",
        "\n",
        "#resultados_PCA = roda_arvore('BASELINE', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'BASELINE', 'PCA', resultados_PCA_tree[0][0],resultados_PCA_tree[0][1], resultados_PCA_tree[0][2], resultados_PCA_tree[0][3],resultados_PCA_tree[0][4],resultados_PCA_tree[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MIM-MAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_MIMMAX_tree = roda_modelo('BASELINE DECISON TREE', 'MIM-MAX', X_train_MIMMAX, y_train_MIMMAX, X_test_MIMMAX, y_test_MIMMAX, dec_clf)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'BASELINE', 'MIM-MAX', resultados_MIMMAX_tree[0][0],resultados_MIMMAX_tree[0][1], resultados_MIMMAX_tree[0][2], resultados_MIMMAX_tree[0][3],resultados_MIMMAX_tree[0][4],resultados_MIMMAX_tree[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_scaler_tree = roda_modelo('BASELINE - DECISION TREE', 'SCALER', X_train_scaler, y_train_scaler, X_test_scaler, y_test_scaler, dec_clf)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'BASELINE', 'SCALER', resultados_scaler_tree[0][0],resultados_scaler_tree[0][1], resultados_scaler_tree[0][2], resultados_scaler_tree[0][3],resultados_scaler_tree[0][4],resultados_scaler_tree[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_robust_tree = roda_modelo('BASELINE DECISION TREE', 'ROBUST', X_train_robust, y_train_robust, X_test_robust, y_test_robust, dec_clf)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'BASELINE', 'ROBUST', resultados_robust_tree[0][0],resultados_robust_tree[0][1], resultados_robust_tree[0][2], resultados_robust_tree[0][3],resultados_robust_tree[0][4],resultados_robust_tree[0][5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# conforme observado o modelo com o menor desvio foi o DECISION TREE REGRESSOR com a normalização MIM-MAX\n",
        "print (\"Modelo com menor desvio\", min(metricas.diferenca_desvio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FIM TESTES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# inicio - deletar após o termino dos testes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L2jaNcFnzkaJ"
      },
      "source": [
        "## Baseline - PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "from sklearn import tree\n",
        "tree.export_graphviz(resultados_robust_tree[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "digraph G {\n",
        "\n",
        "  subgraph cluster_0 {\n",
        "    style=filled;\n",
        "    color=lightgrey;\n",
        "    node [style=filled,color=white];\n",
        "    a0 -> a1 -> a2 -> a3;\n",
        "    label = \"process #1\";\n",
        "  }\n",
        "\n",
        "  subgraph cluster_1 {\n",
        "    node [style=filled];\n",
        "    b0 -> b1 -> b2 -> b3;\n",
        "    label = \"process #2\";\n",
        "    color=blue\n",
        "  }\n",
        "  start -> a0;\n",
        "  start -> b0;\n",
        "  a1 -> b3;\n",
        "  b2 -> a3;\n",
        "  a3 -> a0;\n",
        "  a3 -> end;\n",
        "  b3 -> end;\n",
        "\n",
        "  start [shape=Mdiamond];\n",
        "  end [shape=Msquare];\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "dot_data = export_graphviz(resultados_robust_tree[1], out_file=None, filled=True, rounded=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fim - deletar após o termino dos testes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilizando cross-validation e GridSearchCV para melhorar os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# obtendo quais são os parâmetros disponíveis na árvore, para uso no grid-search\n",
        "dec_clf.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parâmetros a serem avaliados\n",
        "# Escolhi os parâmetros que acredito que são os mais comuns de serem utilizados\n",
        "param_grid = [\n",
        "              {\n",
        "                 'criterion':['mse', 'friedman_mse', 'mae'],\n",
        "                 'max_depth': [5, 20, 100, 400, None], # profundidade máxima da árvore\n",
        "                 'min_samples_split': [2, 50, 300, 1000], # O número mínimo de amostras necessárias para dividir um nó interno\n",
        "                 'min_samples_leaf': [30, 120, 420, 820], # número mínimo de amostras necessárias para estar em um nó folha\n",
        "                 'random_state': [RANDOM_STATE], \n",
        "                 'splitter': ['best']\n",
        "              }\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# execução do gridsearch para definição dos melhores parâmetros\n",
        "gs = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=multiprocessing.cpu_count())\n",
        "gs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# função para rodar o CROSS-VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# função que executa o griserachCV com a lista de parâmetros para definir a configuração com melhor score\n",
        "def definir_parametros (X_train, y_train, gs):\n",
        "    #classes = [0,1,2,3,4,5,6,7,8,9,10]\n",
        "    #gs = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=param_grid, scoring='accuracy', cv=15, n_jobs=multiprocessing.cpu_count())\n",
        "\n",
        "    gs.fit(X_train, y_train) # TREINARNDO A ÁRVORE\n",
        "    # execução do cross-validation com os parâmetros sugeridos pelo gridsearch\n",
        "    cross_val_score(gs.best_estimator_,X_train, y_train,scoring='r2',cv=15).mean()\n",
        "    \n",
        "    \n",
        "    print('Melhor estimador=',gs.best_estimator_)\n",
        "    print(\"Melhor score=\",gs.best_score_ * 100)\n",
        "\n",
        "    return gs.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# INICIO DOS TESTES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_PCA.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# Chama a função que roda o griSerachCV com os dados de treino para obter o melhor estimador\n",
        "tic = time.time()\n",
        "\n",
        "resultados_PCA_CV = definir_parametros(X_train_PCA, y_train_PCA,gs)\n",
        "\n",
        "tac = time.time()\n",
        "# ----------------------------------------\n",
        "\n",
        "# TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "dec_clf_cv.fit(X_train_PCA, y_train_PCA) \n",
        "tempo_que_passou = tac - tic\n",
        "\n",
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_PCA_treecv = roda_modelo('GRIDSEARCHCV + CROSSVALIDATION - DECISION TREE', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA, dec_clf_cv)\n",
        "\n",
        "# impressão do tempo gasto no treino\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armazenando os dados\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'GS + CV', 'PCA', resultados_PCA_treecv[0][0],resultados_PCA_treecv[0][1], resultados_PCA_treecv[0][2], resultados_PCA_treecv[0][3],resultados_PCA_treecv[0][4],resultados_PCA_treecv[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MIM-MAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# Chama a função que roda o griSerachCV com os dados de treino para obter o melhor estimador\n",
        "tic = time.time()\n",
        "\n",
        "resultados_MIMMAX_CV = definir_parametros(X_train_MIMMAX, y_train_MIMMAX)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "# ----------------------------------------\n",
        "\n",
        "# TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "dec_clf_cv.fit(X_train_MIMMAX, y_train_MIMMAX) \n",
        "\n",
        "\n",
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_MIMMAX_treecv = roda_modelo('GRIDSEARCHCV + CROSSVALIDATION - DECISION TREE', 'MIM-MAX', X_train_MIMMAX, y_train_MIMMAX, X_test_MIMMAX, y_test_MIMMAX, dec_clf_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armazenando os dados\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'GS + CV', 'MIM-MAX', resultados_MIMMAX_treecv[0][0],resultados_MIMMAX_treecv[0][1], resultados_MIMMAX_treecv[0][2], resultados_MIMMAX_treecv[0][3],resultados_MIMMAX_treecv[0][4],resultados_MIMMAX_treecv[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# Chama a função que roda o griSerachCV com os dados de treino para obter o melhor estimador\n",
        "tic = time.time()\n",
        "\n",
        "resultados_scaler_CV = definir_parametros(X_train_scaler, y_train_scaler)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "# ----------------------------------------\n",
        "\n",
        "# TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "dec_clf_cv.fit(X_train_scaler, y_train_scaler) \n",
        "\n",
        "\n",
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_scaler_treecv = roda_modelo('GRIDSEARCHCV + CROSSVALIDATION - DECISION TREE', 'Z-Score', X_train_scaler, y_train_scaler, X_test_scaler, y_test_scaler, dec_clf_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armazenando os dados\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'GS + CV', 'SCALER', resultados_scaler_treecv[0][0],resultados_scaler_treecv[0][1], resultados_scaler_treecv[0][2], resultados_scaler_treecv[0][3],resultados_scaler_treecv[0][4],resultados_scaler_treecv[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# Chama a função que roda o griSerachCV com os dados de treino para obter o melhor estimador\n",
        "tic = time.time()\n",
        "\n",
        "resultados_robust_CV = definir_parametros(X_train_robust, y_train_robust)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "# ----------------------------------------\n",
        "\n",
        "# TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "dec_clf_cv.fit(X_train_robust, y_train_robust) \n",
        "\n",
        "\n",
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_robust_treecv = roda_modelo('GRIDSEARCHCV + CROSSVALIDATION - DECISION TREE', 'ROBUST', X_train_robust, y_train_robust, X_test_robust, y_test_robust, dec_clf_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armazenando os dados\n",
        "insert(metricas,['DECISION TREE REGRESSOR', 'GS + CV', 'ROBUST', resultados_robust_treecv[0][0],resultados_robust_treecv[0][1], resultados_robust_treecv[0][2], resultados_robust_treecv[0][3],resultados_robust_treecv[0][4],resultados_robust_treecv[0][5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FIM DOS TESTES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# função que roda a árvore com os parâmetros definidos pelo gridserachCV\n",
        "\n",
        "def insert(df, row):\n",
        "    insert_loc = df.index.max()\n",
        "\n",
        "    if np.isnan(insert_loc):\n",
        "        df.loc[0] = row\n",
        "    else:\n",
        "        df.loc[insert_loc + 1] = row\n",
        "        \n",
        "# CRIA A ARVORE - Os parâmetros definidos pelo GRIDSEARCHCV são iguais para os 4 tipos de dados (PCA, MIMMAX, Z-SCORE, ROBUST)\n",
        "dec_clf_cv = tree.DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth= 5, # profundidade máxima da árvore\n",
        "    min_samples_split= 2, # O número mínimo de amostras necessárias para dividir um nó interno\n",
        "    min_samples_leaf= 80, # número mínimo de amostras necessárias para estar em um nó folha\n",
        "    random_state= RANDOM_STATE, \n",
        "    splitter='best') \n",
        "\n",
        "def roda_arvore_cv (tipo, modelo, X_train, y_train, X_test, y_test):\n",
        "    dec_clf_cv.fit(X_train, y_train) # TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "\n",
        "    desvio_y_original = y_test.std() # calculando o desvio do tareget original\n",
        "    media_original = y_test.mean()\n",
        "\n",
        "    y_pred_cv = dec_clf_cv.predict(X_test) # predizendo o target\n",
        "    desvio_padrao_cv = y_pred_cv.std() # calculando o desvio do dado predito\n",
        "    diferenca_cv = desvio_y_original - desvio_padrao_cv # calculando a diferença entre o desvio dos dados originais e do predito\n",
        "    acuracia_cv = accuracy_score(y_test, y_pred_cv) #calculando a acurácia\n",
        "    media_predita = y_pred_cv.mean()\n",
        "    diferenca_media = media_original - media_predita\n",
        "    print ('BASELINE', '|', modelo, '| Desvio_original:', desvio_y_original.round(3), '| Desvio padrão:', desvio_padrao_cv.round(3), '| Diferença:', diferenca_cv.round(3), '| Acurácia:', acuracia_cv.round(3)*100, ' | Media original:', media_original, ' | media_predita:', media_predita, ' | diferenca_media:', diferenca_media)\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # inserindo os dados no dataframe de metricas\n",
        "    #insert(metricas, [tipo, modelo, desvio_y_original, desvio_padrao, diferenca, acuracia])\n",
        "    # -----------------------------------------------\n",
        "    return dec_clf_cv, y_pred_cv\n",
        "\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Executa o GRIDSEARCHCV com os dados do PCA\n",
        "tic = time.time()\n",
        "\n",
        "resultados_PCA_CV = definir_parametros(X_train_PCA, y_train_PCA)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# RODAR A ÁRVORE COM OS PARAMETROS DEFINIDOS PELO GRIDSERACHCV\n",
        "resultados_PCA_cv = roda_arvore_cv('ÁRVORE COM RESULTADO CV', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_PCA,resultados_PCA_cv[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_PCA_cv[0].classes_), index=(resultados_PCA_cv[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MIMMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "# Executa o GRIDSEARCHCV com os dados do MIMMAX\n",
        "\n",
        "tic = time.time()\n",
        "\n",
        "resultados_MIMMAX_CV = definir_parametros(X_train_MIMMAX, y_train_MIMMAX)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# RODAR A ÁRVORE COM OS PARAMETROS DEFINIDOS PELO GRIDSERACHCV\n",
        "resultados_MIMMAX_cv = roda_arvore_cv('COM GRIDSEARCHCV', 'MIMMAX', X_train_MIMMAX, y_train_MIMMAX, X_test_MIMMAX, y_test_MIMMAX)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_MIMMAX,resultados_MIMMAX_cv[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_MIMMAX_cv[0].classes_), index=(resultados_MIMMAX_cv[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "tic = time.time()\n",
        "\n",
        "resultados_scaler_CV = definir_parametros(X_train_scaler, y_train_scaler)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_scaler_cv = roda_arvore_cv('BASELINE', 'Z-SCORE', X_train_scaler, y_train_scaler, X_test_scaler, y_test_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_scaler,resultados_scaler_cv[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_scaler_cv[0].classes_), index=(resultados_scaler_cv[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "tic = time.time()\n",
        "\n",
        "resultados_robust_CV = definir_parametros(X_train_robust, y_train_robust)\n",
        "\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_robust_cv = roda_arvore('BASELINE', 'Z-SCORE', X_train_robust, y_train_robust, X_test_robust, y_test_robust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_robust,resultados_robust_cv[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_robust_cv[0].classes_), index=(resultados_robust_cv[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELO 2 - RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "def insert(df, row):\n",
        "    insert_loc = df.index.max()\n",
        "\n",
        "    if np.isnan(insert_loc):\n",
        "        df.loc[0] = row\n",
        "    else:\n",
        "        df.loc[insert_loc + 1] = row\n",
        "\n",
        "randonForest = RandomForestRegressor()\n",
        "\n",
        "def roda_random_forest (tipo, modelo, X_train, y_train, X_test, y_test):\n",
        "    randonForest.fit(X_train, y_train) # TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "\n",
        "    desvio_y_original = y_test.std() # calculando o desvio do tareget original\n",
        "    media_original = y_test.mean()\n",
        "\n",
        "    y_pred = randonForest.predict(X_test) # predizendo o target\n",
        "    desvio_padrao = y_pred.std() # calculando o desvio do dado predito\n",
        "    diferenca = desvio_y_original - desvio_padrao # calculando a diferença entre o desvio dos dados originais e do predito\n",
        "    media_predita = y_pred.mean()\n",
        "    diferenca_media = media_original - media_predita\n",
        "    #acuracia = accuracy_score(y_test, y_pred) #calculando a acurácia\n",
        "\n",
        "    print ('BASELINE', '|', modelo, '| Desvio_original:', desvio_y_original.round(3), '| Desvio padrão:', desvio_padrao.round(3), '| Diferença:', diferenca.round(3), #'\\n Acurácia:', acuracia.round(3)*100,\n",
        "    ' \\n Média_original', media_original.round(3), ' | Media predita:', media_predita.round(3), '| Diferença-média', diferenca_media.round(3))\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # inserindo os dados no dataframe de metricas\n",
        "    #insert(metricas, [tipo, modelo, desvio_y_original, desvio_padrao, diferenca, acuracia])\n",
        "    # -----------------------------------------------\n",
        "    return randonForest, y_pred\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# inicio - apagar depois de ajustar todo o código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# criando do dataframe para armazenar as métricas coletadas a cada execução do modelo\n",
        "columns = ['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'] \n",
        "''''\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "metricas = pd.DataFrame(columns=columns)\n",
        "\n",
        "\n",
        "def insert(df, row):\n",
        "    insert_loc = df.index.max()\n",
        "\n",
        "    if np.isnan(insert_loc):\n",
        "        df.loc[0] = row\n",
        "    else:\n",
        "        df.loc[insert_loc + 1] = row\n",
        "\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "def roda_random_forest (tipo, nome_modelo, X_train, y_train, X_test, y_test, modelo):\n",
        "    modelo.fit(X_train, y_train) # TREINANDO A ARVORE COM OS DADOS DE TREINO\n",
        "    y_pred = modelo.predict(X_test) # predizendo o target\n",
        "    \n",
        "    print (\"{} do {}\".format(tipo, nome_modelo))\n",
        "    print (\"\\n\")\n",
        "\n",
        "    classes = [0,1,2,3,4,5,6,7,8,9,10]\n",
        "    resultados = mostra_resultados(y_test, y_pred, classes,tipo, nome_modelo)\n",
        "    \n",
        "    return resultados\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greens):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    \n",
        "    plt.grid(False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "# MOSTRA RESULTADOS\n",
        "def mostra_resultados(y, y_pred, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.coolwarm):\n",
        "\n",
        "    # Calcular os resultados\n",
        "    cm = confusion_matrix(y, y_pred.round(0))\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)  # Falso Positivos\n",
        "    FN = cm.sum(axis=1) - np.diag(cm)  # Falso Negativos\n",
        "    TP = np.diag(cm)                   # Verdadeiro Positivo\n",
        "    TN = cm.sum() - (FP + FN + TP)     # Verdadeiro Negativos\n",
        "    TPR = TP / (TP + FN)  # Revocação    \n",
        "    PPV = TP / (TP + FP)  # Precisao\n",
        "    F1 = 2 * ((PPV * TPR) / (PPV + TPR)) # F1 Score\n",
        "    ACC = (TP + TN) / (TP + FP + FN + TN)  # Acurácia\n",
        "\n",
        "    desvio_y_test = y.std()\n",
        "    desvio_y_pred = y_pred.std()\n",
        "    diferenca_desvio = desvio_y_test - desvio_y_pred\n",
        "\n",
        "    media_y_test = y.mean()\n",
        "    media_y_prev = y_pred.mean()\n",
        "    diferenca_media = media_y_test - media_y_prev\n",
        "\n",
        "    # Exibe resultados\n",
        "    print(\"    Verdadeiros Positivos:{}\".format(TP))\n",
        "    print(\"    Verdadeiros Negativos:{}\".format(TN))\n",
        "    print(\"    Falso Positivo:{}\".format(FP))\n",
        "    print(\"    Falso Negativo:{}\".format(FN))\n",
        "    \n",
        "    print(\"    Revocação:{}\".format(TPR))    \n",
        "    print(\"    Precisao:{}\".format(PPV))\n",
        "    \n",
        "    \n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    print(\"    F1 Score:{}\".format(F1.round(4)))\n",
        "    print(\"    \\nAcuracia:{}\".format(ACC.round(4)*100))\n",
        "\n",
        "    print(\"    \\n Desvio \\n\")\n",
        "    print(\"    y_tes:{}\".format(desvio_y_test.round(4)*100))\n",
        "    print(\"    y_pred:{}\".format(desvio_y_pred.round(4)*100))\n",
        "    print(\"    Diferença:{}\".format(diferenca_desvio.round(4)*100))\n",
        "    \n",
        "    print(\"    \\n Média \\n\")\n",
        "    print(\"    y_tes:{}\".format(media_y_test.round(4)*100))\n",
        "    print(\"    y_pred:{}\".format(media_y_prev.round(4)*100))\n",
        "    print(\"    Diferença:{}\".format(diferenca_media.round(4)*100))\n",
        "    \n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    plot_confusion_matrix(cm, classes)\n",
        "\n",
        "    return desvio_y_test, desvio_y_pred, diferenca_desvio, media_y_test, media_y_prev, diferenca_media, y_pred\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fim - apagar depois de ajustar todo o código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando o modelo\n",
        "randonForest = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "randonForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_PCA_randomForest = roda_modelo('BASELINE RANDON FOREST', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA, randonForest)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['RANDOM FOREST REGRESSOR', 'BASELINE', 'PCA', resultados_PCA_randomForest[0][0],resultados_PCA_randomForest[0][1], resultados_PCA_randomForest[0][2], resultados_PCA_randomForest[0][3],resultados_PCA_randomForest[0][4],resultados_PCA_randomForest[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MIMMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_MIMMAX_randomForest = roda_modelo('BASELINE RANDON FOREST', 'MIM-MAX', X_train_MIMMAX, y_train_MIMMAX, X_test_MIMMAX, y_test_MIMMAX, randonForest)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['RANDOM FOREST REGRESSOR', 'BASELINE', 'PCA', resultados_MIMMAX_randomForest[0][0],resultados_MIMMAX_randomForest[0][1], resultados_MIMMAX_randomForest[0][2], resultados_MIMMAX_randomForest[0][3],resultados_MIMMAX_randomForest[0][4],resultados_MIMMAX_randomForest[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_scaler_randomForest = roda_modelo('BASELINE RANDON FOREST', 'SCALER', X_train_scaler, y_train_scaler, X_test_scaler, y_test_scaler, randonForest)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['RANDOM FOREST REGRESSOR', 'BASELINE', 'SCALER', resultados_scaler_randomForest[0][0],resultados_scaler_randomForest[0][1], resultados_scaler_randomForest[0][2], resultados_scaler_randomForest[0][3],resultados_scaler_randomForest[0][4],resultados_scaler_randomForest[0][5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Executando o modelo, gerando os resuldos e plotando a matriz de confusão\n",
        "resultados_robust_randomForest = roda_modelo('BASELINE RANDON FOREST', 'ROBUST', X_train_robust, y_train_robust, X_test_robust, y_test_robust, randonForest)\n",
        "\n",
        "# Armazenando os dados\n",
        "''''\n",
        "insert(metricas,['nome_modelo', 'tipo_predicao', 'tipo_dado', 'desvio_original','desvio_pred', 'diferenca_desvio', 'media_original', 'media_predita', 'diferenca_media'])\n",
        "# NOME_MODELO: 'DECISON TREE REGRESSOR', 'RANDOM FOREST REGRESSOR'\n",
        "# TIPO_PREDICAO: BASELINE, CROSS VALIDATION + GRIDSEARCHCV\n",
        "# TIPO_DADO: PCA, MIMMAX, SCALER, ROBUST\n",
        "'''\n",
        "insert(metricas,['RANDOM FOREST REGRESSOR', 'BASELINE', 'ROBUST', resultados_robust_randomForest[0][0],resultados_robust_randomForest[0][1], resultados_robust_randomForest[0][2], resultados_robust_randomForest[0][3],resultados_robust_randomForest[0][4],resultados_robust_randomForest[0][5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# INICIO EXCLUIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RESULTADO DA PREDIÇÃO SEM GRIDSEARCH + CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_PCA_randomForest = roda_random_forest('BASELINE RANDON FOREST', 'PCA', X_train_PCA, y_train_PCA, X_test_PCA, y_test_PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_robust,resultados_PCA_randomForest[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_PCA_randomForest[0].classes_), index=(resultados_PCA_randomForest[0].classes_))\n",
        "111"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MINMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_MIMMAX_randomForest = roda_random_forest('BASELINE RANDON FOREST', 'MIMMAX', X_train_MIMMAX, y_train_MIMMAX, X_test_MIMMAX, y_test_MIMMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_robust,resultados_MIMMAX_randomForest[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_MIMMAX_randomForest[0].classes_), index=(resultados_MIMMAX_randomForest[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Z-SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_scaler_randomForest = roda_random_forest('BASELINE RANDON FOREST', 'scaler', X_train_scaler, y_train_scaler, X_test_scaler, y_test_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_robust,resultados_scaler_randomForest[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_scaler_randomForest[0].classes_), index=(resultados_scaler_randomForest[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROBUST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#resultados_robust_randomForest = roda_random_forest('BASELINE RANDON FOREST', 'robust', X_train_robust, y_train_robust, X_test_robust, y_test_robust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Compara o resultado do modelo com o resultado verdadeiro\n",
        "cnf_matrix = confusion_matrix(y_test_robust,resultados_robust_randomForest[1])\n",
        "\n",
        "# Constrói um Dataframe com a matriz de confusão apenas para ficar mais legível\n",
        "pd.DataFrame(cnf_matrix, columns=(resultados_robust_randomForest[0].classes_), index=(resultados_robust_randomForest[0].classes_))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mostra_resultados(y_test, y_pred, modelo.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FIM EXCLUIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RESULTADO DA PREDIÇÃO COM GRIDSEARCH + CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
        "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\n",
        "                      min_impurity_split=None, min_samples_leaf=1,\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
        "                      random_state=None, verbose=0, warm_start=False\n",
        "\n",
        "'''\n",
        "'''\n",
        "tree\n",
        "\n",
        "                 'criterion':['gini', 'entropia'],\n",
        "                 'max_depth': [5, 20, 100, 400, None], # profundidade máxima da árvore\n",
        "                 'min_samples_split': [2, 50, 300, 1000], # O número mínimo de amostras necessárias para dividir um nó interno\n",
        "                 'min_samples_leaf': [30, 120, 420, 820], # número mínimo de amostras necessárias para estar em um nó folha\n",
        "                 'random_state': [RANDOM_STATE], \n",
        "                 'splitter': ['best']\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# obtendo quais são os parâmetros disponíveis na árvore, para uso no grid-search\n",
        "randonForest.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARAMETROS DO GRID SEARCH CV\n",
        "parametros_grid_randomForest = {\n",
        "    \"n_estimators\": [10, 50, 100, 200, 400], # O número de árvores na floresta.\n",
        "    \"max_depth\": [5, 20, 100, 400, None], # profundidade máxima da árvore\n",
        "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"], # \n",
        "    \"min_samples_split\": [2, 50, 300, 1000], # número mínimo de amostras necessárias para dividir um nó interno\n",
        "    \"min_samples_leaf\": [30, 120, 420, 820],  # número mínimo de amostras necessárias para estar em um nó folha\n",
        "    \"bootstrap\": [True], # amostragem de dados\n",
        "    'random_state': [RANDOM_STATE]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QUANTIDADE DE FOLDS \n",
        "n_cross_validation = 5\n",
        "\n",
        "# USAR \"ACURÁCIA\" COMO CRITÉRIO PARA ENCONTRAR O MELHOR MODELO\n",
        "criterio = \"accuracy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "radomForest_cv = GridSearchCV(RandomForestRegressor(),\n",
        "                      param_grid=parametros_grid_randomForest, cv=n_cross_validation, verbose=10, scoring=criterio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# APLICANDO O TREINO\n",
        "radomForest_cv.fit(X_train_PCA, y_train_PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXTRAINDO O MELHOR MODELO\n",
        "melhor_modelo = radomForest_cv.best_estimator_\n",
        "\n",
        "# PREDIÇÃO TESTE\n",
        "y_pred = melhor_modelo.predict(X_test_PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TExXJPSgzkb3",
        "colab_type": "text"
      },
      "source": [
        "6. **Apresente (com visualizações) os resultados do seu modelo mostrando que ele é melhor do que um baseline não aleatório.**\n",
        "    * Para o baseline, você pode escolher um modelo bem trivial mas não aleatório. Por exemplo, para um problema de classificação um baseline pode ser a classe mais presente caso o conjunto de dados seja desbalanceado.  Um modelo mais simples também pode ser utilizado como baseline, por exemplo, você escolheu um Random Forest Classifier, e comparou os resultados um Logistic Regression. Você pode até mesmo escolher um modelo de AutoML(como TPOT) como Baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Rzjgauzkb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5qMrhL-zkcL",
        "colab_type": "text"
      },
      "source": [
        "### 6) Conclusões **10%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIA2bbNUzkcO",
        "colab_type": "text"
      },
      "source": [
        "*Partindo das suas hipoteses e investigações, o que você consegue concluir? Suas hipoteses se concretizaram?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBW0AptvzkcS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}